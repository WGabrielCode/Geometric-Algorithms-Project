{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt: Lokalizacja punktu w przestrzeni dwuwymiarowej – Metoda Separatorów\n",
    "**Autor:** Gabriel\n",
    "**Przedmiot:** Algorytmy Geometryczne\n",
    "\n",
    "## 1. Wstęp Teoretyczny\n",
    "[cite_start]Problem lokalizacji punktu polega na znalezieniu regionu $R_i$ w podziale płaszczyzny, który zawiera dany punkt zapytania $p$[cite: 13]. W tym projekcie prezentujemy **Metodę Łańcuchów (Chain Method)**, znaną również jako metoda separatorów.\n",
    "\n",
    "### Główne założenia metody:\n",
    "1.  **Monotoniczność:** Podział płaszczyzny składa się z obszarów monotonicznych. [cite_start]Jeśli obszary nie są monotoniczne, wymagana jest regularyzacja (np. triangulacja)[cite: 104].\n",
    "2.  [cite_start]**Separatory (Łańcuchy):** Konstruujemy zbiór łańcuchów monotonicznych, które uporządkowują obszary od lewej do prawej[cite: 14].\n",
    "\n",
    "[cite_start]Struktura danych to drzewo binarne, gdzie węzły reprezentują łańcuchy, a liście reprezentują regiony[cite: 30]. Zapytanie o punkt polega na dyskryminacji (porównaniu) położenia punktu względem kolejnych łańcuchów w drzewie, co pozwala na osiągnięcie logarytmicznego czasu zapytania.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.376357Z",
     "start_time": "2026-01-07T01:01:01.371765Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List , Tuple , Optional , Union , Any\n",
    "from functools import cmp_to_key\n",
    "from data import raw\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bitalg.visualizer.main import Visualizer\n",
    "from time import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.389787Z",
     "start_time": "2026-01-07T01:01:01.384660Z"
    }
   },
   "outputs": [],
   "source": [
    "TOLERANCE = 1e-24\n",
    "\n",
    "# Data Structures\n",
    "\n",
    "class Vertex:\n",
    "    def __init__(self, x_coord: float, y_coord: float):\n",
    "        self.x = x_coord\n",
    "        self.y = y_coord\n",
    "        self.adj_out: List[Tuple['Vertex', int]] = []\n",
    "        self.adj_in: List[Tuple['Vertex', int]] = []\n",
    "        self.accumulated_weight_in = 0\n",
    "        self.accumulated_weight_out = 0\n",
    "\n",
    "    @property\n",
    "    def coords(self) -> Tuple[float, float]:\n",
    "        return self.x, self.y\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"V({self.x:.2f}, {self.y:.2f})\"\n",
    "\n",
    "class MonotoneChain:\n",
    "    def __init__(self):\n",
    "        self.path_vertices: List[Tuple[float, float]] = []\n",
    "        self.path_segments: List[Tuple[Tuple[float, float], Tuple[float, float]]] = []\n",
    "\n",
    "    def add_node(self, coords: Tuple[float, float]):\n",
    "        self.path_vertices.append(coords)\n",
    "\n",
    "    def add_segment(self, start: Tuple[float, float], end: Tuple[float, float]):\n",
    "        self.path_segments.append((start, end))\n",
    "\n",
    "class SearchTreeNode:\n",
    "    def __init__(self, segments: List, chain_ref: MonotoneChain, parent: Optional['SearchTreeNode'] = None):\n",
    "        self.left_child: Optional[SearchTreeNode] = None\n",
    "        self.right_child: Optional[SearchTreeNode] = None\n",
    "        self.parent = parent\n",
    "        self.segments = segments\n",
    "        self.chain_ref = chain_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Przetwarzanie Grafu i Wagi Planarne\n",
    "Aby zbudować drzewo łańcuchów, musimy najpierw odpowiednio skierować krawędzie i nadać im wagi. Algorytm wykonuje dwa przejścia:\n",
    "1.  **Forward pass:** Propagacja wag z dołu do góry.\n",
    "2.  **Backward pass:** Korekta wag z góry na dół.\n",
    "\n",
    "[cite_start]Celem jest ustalenie przepływu tak, aby każdy łańcuch mógł zostać wyodrębniony jako ścieżka monotoniczna od źródła do ujścia grafu[cite: 33]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.403100Z",
     "start_time": "2026-01-07T01:01:01.395598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Geometry Utils\n",
    "\n",
    "def cross_product(o: Tuple[float, float], a: Tuple[float, float], b: Tuple[float, float]) -> float:\n",
    "    return (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0])\n",
    "\n",
    "# Graph Processing\n",
    "\n",
    "def build_graph(raw_vertices: List[Tuple[float, float]], raw_edges: List[Tuple[int, int]]) -> List[Vertex]:\n",
    "    graph_nodes = [Vertex(x, y) for x, y in raw_vertices]\n",
    "    for start_idx, end_idx in raw_edges:\n",
    "        # Ensure edges point upwards (or rightwards for equal Y) to maintain DAG property\n",
    "        u, v = sorted((start_idx, end_idx))\n",
    "        node_u = graph_nodes[u]\n",
    "        node_v = graph_nodes[v]\n",
    "        node_u.adj_out.append((node_v, 1))\n",
    "        node_v.adj_in.append((node_u, 1))\n",
    "    return graph_nodes\n",
    "\n",
    "def compute_planar_weights(graph: List[Vertex]):\n",
    "    for node in graph:\n",
    "        center = node.coords\n",
    "        \n",
    "        # Sort edges angularly to identify \"leftmost\" and \"rightmost\" paths\n",
    "        def angular_comparator(edge1, edge2):\n",
    "            p1 = edge1[0].coords\n",
    "            p2 = edge2[0].coords\n",
    "            cp = cross_product(center, p1, p2)\n",
    "            if math.isclose(cp, 0, abs_tol=TOLERANCE): return 0\n",
    "            return -1 if cp > 0 else 1\n",
    "\n",
    "        node.adj_out.sort(key=cmp_to_key(angular_comparator))\n",
    "        node.adj_in.sort(key=cmp_to_key(lambda a, b: -1 * angular_comparator(a, b)))\n",
    "\n",
    "    # Forward pass: Propagate weights from bottom to top\n",
    "    for i in range(1, len(graph) - 1):\n",
    "        v = graph[i]\n",
    "        v.accumulated_weight_in = sum(w for _, w in v.adj_in)\n",
    "        v.accumulated_weight_out = len(v.adj_out)\n",
    "        \n",
    "        # if input flow > output flow, push excess to leftmost outgoing edge\n",
    "        if v.accumulated_weight_in > v.accumulated_weight_out:\n",
    "            target_node, current_w = v.adj_out.pop(0)\n",
    "            new_weight = current_w + v.accumulated_weight_in - v.accumulated_weight_out\n",
    "            v.adj_out.insert(0, (target_node, new_weight))\n",
    "            \n",
    "            # Update the corresponding incoming edge at the target node\n",
    "            for idx, (neighbor, w) in enumerate(target_node.adj_in):\n",
    "                if neighbor == v:\n",
    "                    target_node.adj_in[idx] = (v, new_weight)\n",
    "                    break\n",
    "\n",
    "    # Backward pass: Propagate weights from top to bottom\n",
    "    for i in range(len(graph) - 2, 0, -1):\n",
    "        v = graph[i]\n",
    "        v.accumulated_weight_in = sum(w for _, w in v.adj_in)\n",
    "        v.accumulated_weight_out = sum(w for _, w in v.adj_out)\n",
    "        \n",
    "        # If output flow > input flow, pull excess from leftmost incoming edge\n",
    "        if v.accumulated_weight_out > v.accumulated_weight_in:\n",
    "            source_node, current_w = v.adj_in.pop(0)\n",
    "            new_weight = current_w + v.accumulated_weight_out - v.accumulated_weight_in\n",
    "            v.adj_in.insert(0, (source_node, new_weight))\n",
    "            \n",
    "            for idx, (neighbor, w) in enumerate(source_node.adj_out):\n",
    "                if neighbor == v:\n",
    "                    source_node.adj_out[idx] = (v, new_weight)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generowanie Łańcuchów Monotonicznych i Struktura Wyszukiwania\n",
    "Algorytm zachłannie buduje łańcuchy, \"konsumując\" wagi krawędzi. Powstałe łańcuchy są następnie organizowane w zbalansowane drzewo poszukiwań binarnego (BST).\n",
    "\n",
    "* **Liście drzewa:** Odpowiadają regionom.\n",
    "[cite_start]* **Węzły wewnętrzne:** Odpowiadają łańcuchom (separatorom)[cite: 31].\n",
    "Drzewo to pozwala na szybkie określenie, po której stronie separatora znajduje się punkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.414740Z",
     "start_time": "2026-01-07T01:01:01.408825Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_monotone_chains(graph: List[Vertex]) -> List[MonotoneChain]:\n",
    "    source_node = graph[0]\n",
    "    total_chains = sum(w for _, w in source_node.adj_out)\n",
    "    chains = [MonotoneChain() for _ in range(total_chains)]\n",
    "    \n",
    "    for chain in chains:\n",
    "        current_v = source_node\n",
    "        \n",
    "        # Traverse graph greedily consuming edge weights\n",
    "        while current_v.adj_out:\n",
    "            chain.add_node(current_v.coords)\n",
    "            chosen_idx = -1\n",
    "            \n",
    "            # Pick the rightmost available edge (non-zero weight)\n",
    "            for i in range(len(current_v.adj_out) - 1, -1, -1):\n",
    "                neighbor, weight = current_v.adj_out[i]\n",
    "                if weight > 0:\n",
    "                    chosen_idx = i\n",
    "                    break\n",
    "            if chosen_idx == -1: break\n",
    "            \n",
    "            next_v, w = current_v.adj_out[chosen_idx]\n",
    "            current_v.adj_out[chosen_idx] = (next_v, w - 1) # Decrease capacity\n",
    "            current_v = next_v\n",
    "            \n",
    "        chain.add_node(current_v.coords)\n",
    "        \n",
    "        verts = chain.path_vertices\n",
    "        for k in range(len(verts) - 1):\n",
    "            chain.add_segment(verts[k], verts[k+1])\n",
    "    return chains\n",
    "\n",
    "def create_search_structure(chains: List[MonotoneChain], parent: Optional[SearchTreeNode] = None) -> Optional[SearchTreeNode]:\n",
    "    if not chains: return None\n",
    "    mid_idx = len(chains) // 2\n",
    "    median_chain = chains[mid_idx]\n",
    "    \n",
    "    node = SearchTreeNode(median_chain.path_segments, median_chain, parent)\n",
    "    node.left_child = create_search_structure(chains[:mid_idx], node)\n",
    "    node.right_child = create_search_structure(chains[mid_idx + 1:], node)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logika Zapytania (Point Location)\n",
    "Dla zadanego punktu $p$ algorytm schodzi w dół drzewa. W każdym węźle sprawdzamy relację punktu względem separatora:\n",
    "* Jeśli punkt jest na lewo od separatora -> idziemy do lewego dziecka.\n",
    "[cite_start]* Jeśli punkt jest na prawo od separatora -> idziemy do prawego dziecka [cite: 49-50].\n",
    "\n",
    "Test relacji wykorzystuje iloczyn wektorowy (`cross_product`) oraz wyszukiwanie binarne na segmentach separatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.430237Z",
     "start_time": "2026-01-07T01:01:01.420187Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query Logic\n",
    "\n",
    "def find_position_relative_to_chain(point: Tuple[float, float], node: SearchTreeNode) -> int:\n",
    "    px, py = point\n",
    "    segments = node.segments\n",
    "    target_segment = None\n",
    "    \n",
    "    # Binary Search to find the segment covering the point's Y-coordinate\n",
    "    left_idx, right_idx = 0, len(segments) - 1\n",
    "    \n",
    "    while left_idx <= right_idx:\n",
    "        mid_idx = (left_idx + right_idx) // 2\n",
    "        p1, p2 = segments[mid_idx]\n",
    "        \n",
    "        y_min, y_max = p1[1], p2[1]\n",
    "        \n",
    "        if y_min - TOLERANCE <= py <= y_max + TOLERANCE:\n",
    "            target_segment = (p1, p2)\n",
    "            break\n",
    "        elif py < y_min:\n",
    "            right_idx = mid_idx - 1\n",
    "        else:\n",
    "            left_idx = mid_idx + 1\n",
    "            \n",
    "    if target_segment is None: \n",
    "        return 1\n",
    "    \n",
    "    cp = cross_product(target_segment[0], target_segment[1], point)\n",
    "    \n",
    "    if math.isclose(cp, 0, abs_tol=TOLERANCE):\n",
    "        # Handle collinear points: check if strictly inside segment bounds\n",
    "        min_x = min(target_segment[0][0], target_segment[1][0])\n",
    "        max_x = max(target_segment[0][0], target_segment[1][0])\n",
    "        if min_x <= px <= max_x:\n",
    "            return 0 \n",
    "        return -1 if px > target_segment[0][0] else 1\n",
    "    \n",
    "    # Return -1 for Right, 1 for Left\n",
    "    return -1 if cp < 0 else 1\n",
    "\n",
    "def query_search_tree(point: Tuple[float, float], node: Optional[SearchTreeNode], \n",
    "                     closest_left: Optional[MonotoneChain] = None,\n",
    "                     closest_right: Optional[MonotoneChain] = None) -> Union[MonotoneChain, Tuple[MonotoneChain, MonotoneChain]]:\n",
    "    if node is None:\n",
    "        return (closest_left, closest_right)\n",
    "        \n",
    "    position = find_position_relative_to_chain(point, node)\n",
    "    \n",
    "    if position == 0:\n",
    "        return node.chain_ref\n",
    "        \n",
    "    # Traverse BST based on point position relative to current separator\n",
    "    if position < 0:\n",
    "        return query_search_tree(point, node.right_child, closest_left=node.chain_ref, closest_right=closest_right)\n",
    "    else: \n",
    "        return query_search_tree(point, node.left_child, closest_left=closest_left, closest_right=node.chain_ref)\n",
    "\n",
    "def extract_region_edges(chain_a: MonotoneChain, chain_b: MonotoneChain, point: Tuple[float, float]) -> List[Tuple]:\n",
    "    if chain_a is None: return chain_b.path_segments \n",
    "    if chain_b is None: return chain_a.path_segments\n",
    "\n",
    "    verts_a = chain_a.path_vertices\n",
    "    verts_b = chain_b.path_vertices\n",
    "    \n",
    "    bubbles = []\n",
    "    i, j = 0, 0\n",
    "    last_common_a_idx = 0\n",
    "    last_common_b_idx = 0\n",
    "    \n",
    "    # Iterate through both chains to find split and merge points (\"bubbles\")\n",
    "    while i < len(verts_a) and j < len(verts_b):\n",
    "        va = verts_a[i]\n",
    "        vb = verts_b[j]\n",
    "        \n",
    "        is_same = math.isclose(va[0], vb[0], abs_tol=TOLERANCE) and math.isclose(va[1], vb[1], abs_tol=TOLERANCE)\n",
    "        \n",
    "        if is_same:\n",
    "            if i > last_common_a_idx or j > last_common_b_idx:\n",
    "                # Close the bubble and store it\n",
    "                bubble_a = verts_a[last_common_a_idx : i+1]\n",
    "                bubble_b = verts_b[last_common_b_idx : j+1]\n",
    "                bubbles.append((bubble_a, bubble_b))\n",
    "                \n",
    "            last_common_a_idx = i\n",
    "            last_common_b_idx = j\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            # Advance pointer for the geometrically lower vertex\n",
    "            if va[1] < vb[1] or (math.isclose(va[1], vb[1]) and va[0] < vb[0]):\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "                \n",
    "    py = point[1]\n",
    "    result_edges = []\n",
    "    \n",
    "    # Find which bubble contains the query point Y-coordinate\n",
    "    for path_a, path_b in bubbles:\n",
    "        min_y = min(v[1] for v in path_a + path_b)\n",
    "        max_y = max(v[1] for v in path_a + path_b)\n",
    "        \n",
    "        if min_y <= py <= max_y:\n",
    "            # Collect unique edges from both sides of the bubble\n",
    "            for k in range(len(path_a) - 1):\n",
    "                result_edges.append((path_a[k], path_a[k+1]))\n",
    "            for k in range(len(path_b) - 1):\n",
    "                edge = (path_b[k], path_b[k+1])\n",
    "                if edge not in result_edges:\n",
    "                    result_edges.append(edge)\n",
    "            if result_edges:\n",
    "                return result_edges\n",
    "\n",
    "    return result_edges\n",
    "\n",
    "# Main API\n",
    "\n",
    "def run_point_location(vertices: List[Tuple[float, float]], edges: List[Tuple[int, int]], query_point: Tuple[float, float]):\n",
    "    graph = build_graph(vertices, edges)\n",
    "    compute_planar_weights(graph)\n",
    "    separators = generate_monotone_chains(graph)\n",
    "    bst_root = create_search_structure(separators)\n",
    "    \n",
    "    result = query_search_tree(query_point, bst_root, closest_left=separators[0], closest_right=separators[-1])\n",
    "    \n",
    "    # Handle point exactly on a separator\n",
    "    if isinstance(result, MonotoneChain):\n",
    "        segments = result.path_segments\n",
    "        l, r = 0, len(segments) - 1\n",
    "        while l <= r:\n",
    "            mid = (l + r) // 2\n",
    "            seg = segments[mid]\n",
    "            if seg[0][1] <= query_point[1] <= seg[1][1]:\n",
    "                return [seg]\n",
    "            elif query_point[1] < seg[0][1]:\n",
    "                r = mid - 1\n",
    "            else:\n",
    "                l = mid + 1\n",
    "        return result.path_segments\n",
    "        \n",
    "    # Handle point inside a region\n",
    "    sep_left, sep_right = result\n",
    "    return extract_region_edges(sep_left, sep_right, query_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.444313Z",
     "start_time": "2026-01-07T01:01:01.436677Z"
    }
   },
   "outputs": [],
   "source": [
    "def separators_method_point_location_algorithm_visualiser(raw_vertices, raw_edges, point):\n",
    "    try:\n",
    "        from bitalg.visualizer.main import Visualizer\n",
    "    except ImportError:\n",
    "        return None, run_point_location(raw_vertices, raw_edges, point)\n",
    "\n",
    "    vis = Visualizer()\n",
    "    vis.add_point(raw_vertices, color=\"black\")\n",
    "    \n",
    "    segments = []\n",
    "    for u, v in raw_edges:\n",
    "        p1 = raw_vertices[u]\n",
    "        p2 = raw_vertices[v]\n",
    "        segments.append((p1, p2))\n",
    "    vis.add_line_segment(segments, color=\"gray\")\n",
    "    \n",
    "    found_edges = run_point_location(raw_vertices, raw_edges, point)\n",
    "    \n",
    "    vis.add_point(point, color=\"green\")\n",
    "    if found_edges:\n",
    "        vis.add_line_segment(found_edges, color=\"red\", linewidth=3)\n",
    "        \n",
    "    return vis, found_edges\n",
    "\n",
    "def animate_point_location(raw_vertices: List[Tuple[float, float]], \n",
    "                           raw_edges: List[Tuple[int, int]], \n",
    "                           query_point: Tuple[float, float]):\n",
    "    \"\"\"\n",
    "    Tworzy animację (GIF) działania algorytmu lokalizacji punktu.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from bitalg.visualizer.main import Visualizer\n",
    "    except ImportError:\n",
    "        print(\"Brak biblioteki bitalg.\")\n",
    "        return None\n",
    "\n",
    "    # 1. Building structures\n",
    "    graph = build_graph(raw_vertices, raw_edges)\n",
    "    compute_planar_weights(graph)\n",
    "    separators = generate_monotone_chains(graph)\n",
    "    bst_root = create_search_structure(separators)\n",
    "    \n",
    "    # 2. Visualizer\n",
    "    vis = Visualizer()\n",
    "    \n",
    "    # drawing input graph\n",
    "    vis.add_point(raw_vertices, color=\"black\", s=5)\n",
    "    \n",
    "    all_segments = []\n",
    "    for u, v in raw_edges:\n",
    "        p1 = raw_vertices[u]\n",
    "        p2 = raw_vertices[v]\n",
    "        all_segments.append((p1, p2))\n",
    "    vis.add_line_segment(all_segments, color=\"lightgray\", linewidth=1)\n",
    "    \n",
    "    # query point\n",
    "    vis.add_point([query_point], color=\"green\", s=20)\n",
    "    \n",
    "    # 3. animation loop\n",
    "    current_node = bst_root\n",
    "    \n",
    "    while current_node is not None:\n",
    "        # A. show current separator\n",
    "        chain_segments = current_node.segments\n",
    "        chain_fig = vis.add_line_segment(chain_segments, color=\"orange\", linewidth=2)\n",
    "        \n",
    "        # B. find segment on separator what alligns with query point, using binsearch\n",
    "        px, py = query_point\n",
    "        target_segment = None\n",
    "        left_idx, right_idx = 0, len(chain_segments) - 1\n",
    "        \n",
    "        while left_idx <= right_idx:\n",
    "            mid_idx = (left_idx + right_idx) // 2\n",
    "            p1, p2 = chain_segments[mid_idx]\n",
    "            y_min, y_max = p1[1], p2[1]\n",
    "            \n",
    "            if y_min - TOLERANCE <= py <= y_max + TOLERANCE:\n",
    "                target_segment = (p1, p2)\n",
    "                break\n",
    "            elif py < y_min:\n",
    "                right_idx = mid_idx - 1\n",
    "            else:\n",
    "                left_idx = mid_idx + 1\n",
    "        \n",
    "        seg_fig = None\n",
    "        position = 1 # default case\n",
    "\n",
    "        if target_segment:\n",
    "            # C. show curretn segment\n",
    "            seg_fig = vis.add_line_segment([target_segment], color=\"blue\", linewidth=4)\n",
    "            \n",
    "            # calculate position\n",
    "            cp = cross_product(target_segment[0], target_segment[1], query_point)\n",
    "            if math.isclose(cp, 0, abs_tol=TOLERANCE):\n",
    "                position = 0 # collinear\n",
    "            else:\n",
    "                position = -1 if cp < 0 else 1\n",
    "        \n",
    "        # D. deeting figure for animation\n",
    "        if seg_fig:\n",
    "            vis.remove_figure(seg_fig)\n",
    "        \n",
    "        vis.remove_figure(chain_fig)\n",
    "        \n",
    "        # E. traversing BST\n",
    "        if position == 0:\n",
    "            break # collinear\n",
    "        elif position < 0:\n",
    "            current_node = current_node.right_child\n",
    "        else:\n",
    "            current_node = current_node.left_child\n",
    "\n",
    "    # 4. show final polygon\n",
    "    found_edges = run_point_location(raw_vertices, raw_edges, query_point)\n",
    "    if found_edges:\n",
    "        vis.add_line_segment(found_edges, color=\"red\", linewidth=3)\n",
    "        \n",
    "    return vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Obsługa Dowolnych Wielokątów (Pre-processing)\n",
    "Ponieważ metoda łańcuchów wymaga regionów monotonicznych, dowolne wielokąty (w tym wklęsłe) muszą zostać poddane obróbce. Stosujemy tutaj metodę **Ear Clipping** do triangulacji wielokątów.\n",
    "\n",
    "[cite_start]Powstały graf trójkątów może być niespójny (zawierać \"wyspy\"), dlatego funkcja `patch_graph_connectivity` dodaje wirtualne krawędzie łączące, tworząc spójny graf wymagany przez algorytm[cite: 104]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.462210Z",
     "start_time": "2026-01-07T01:01:01.450607Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# WORK IN PROGRESS\n",
    "\n",
    "def cross_product(o, a, b):\n",
    "    return (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0])\n",
    "\n",
    "def is_point_in_triangle(p, a, b, c):\n",
    "    cp1 = cross_product(a, b, p)\n",
    "    cp2 = cross_product(b, c, p)\n",
    "    cp3 = cross_product(c, a, p)\n",
    "    has_neg = (cp1 < 0) or (cp2 < 0) or (cp3 < 0)\n",
    "    has_pos = (cp1 > 0) or (cp2 > 0) or (cp3 > 0)\n",
    "    return not (has_neg and has_pos)\n",
    "\n",
    "def get_polygon_signed_area(points):\n",
    "    area = 0.0\n",
    "    for i in range(len(points)):\n",
    "        j = (i + 1) % len(points)\n",
    "        area += points[i][0] * points[j][1]\n",
    "        area -= points[j][0] * points[i][1]\n",
    "    return area / 2.0\n",
    "\n",
    "def triangulate_indices(indices, vertices):\n",
    "    local_indices = indices[:]\n",
    "    triangles = []\n",
    "    n = len(local_indices)\n",
    "    max_iter = n * n \n",
    "    count = 0\n",
    "    \n",
    "    while len(local_indices) > 2:\n",
    "        if count > max_iter:\n",
    "            break\n",
    "        n_curr = len(local_indices)\n",
    "        ear_found = False\n",
    "        for i in range(n_curr):\n",
    "            prev_idx = local_indices[(i - 1) % n_curr]\n",
    "            curr_idx = local_indices[i]\n",
    "            next_idx = local_indices[(i + 1) % n_curr]\n",
    "            \n",
    "            p_prev = vertices[prev_idx]\n",
    "            p_curr = vertices[curr_idx]\n",
    "            p_next = vertices[next_idx]\n",
    "            \n",
    "            if cross_product(p_prev, p_curr, p_next) > 0.0000001:\n",
    "                is_ear = True\n",
    "                for k in range(n_curr):\n",
    "                    test_idx = local_indices[k]\n",
    "                    if test_idx in (prev_idx, curr_idx, next_idx): continue\n",
    "                    if is_point_in_triangle(vertices[test_idx], p_prev, p_curr, p_next):\n",
    "                        is_ear = False\n",
    "                        break\n",
    "                if is_ear:\n",
    "                    triangles.append((prev_idx, curr_idx, next_idx))\n",
    "                    local_indices.pop(i)\n",
    "                    ear_found = True\n",
    "                    break\n",
    "        if not ear_found: local_indices.pop(0)\n",
    "        count += 1\n",
    "    return triangles\n",
    "\n",
    "def process_polygons_to_mesh(polygons_list):\n",
    "    \"\"\"\n",
    "    Tworzy siatkę, a na końcu sortuje wierzchołki rosnąco po Y (i X dla stabilności)\n",
    "    oraz aktualizuje indeksy krawędzi.\n",
    "    \"\"\"\n",
    "    temp_vertices = []\n",
    "    vertex_map = {} \n",
    "    all_edges = set() \n",
    "    \n",
    "    def get_vertex_index(pt):\n",
    "        pt_tuple = (round(pt[0], 6), round(pt[1], 6))\n",
    "        if pt_tuple not in vertex_map:\n",
    "            vertex_map[pt_tuple] = len(temp_vertices)\n",
    "            temp_vertices.append(pt_tuple)\n",
    "        return vertex_map[pt_tuple]\n",
    "\n",
    "    for poly in polygons_list:\n",
    "        if len(poly) < 3: continue\n",
    "        poly_indices = [get_vertex_index(p) for p in poly]\n",
    "        \n",
    "        original_coords = [temp_vertices[i] for i in poly_indices]\n",
    "        if get_polygon_signed_area(original_coords) < 0:\n",
    "            poly_indices.reverse()\n",
    "            \n",
    "        tris = triangulate_indices(poly_indices, temp_vertices)\n",
    "        \n",
    "        for (i1, i2, i3) in tris:\n",
    "            all_edges.add(tuple(sorted((i1, i2))))\n",
    "            all_edges.add(tuple(sorted((i2, i3))))\n",
    "            all_edges.add(tuple(sorted((i3, i1))))\n",
    "\n",
    "    indexed_vertices = list(enumerate(temp_vertices))\n",
    "    \n",
    "    indexed_vertices.sort(key=lambda x: (x[1][1], x[1][0]))\n",
    "    \n",
    "    sorted_vertices = []\n",
    "    old_to_new_map = {}\n",
    "    \n",
    "    for new_idx, (old_idx, pt) in enumerate(indexed_vertices):\n",
    "        sorted_vertices.append(pt)\n",
    "        old_to_new_map[old_idx] = new_idx\n",
    "        \n",
    "    final_edges = []\n",
    "    for u, v in all_edges:\n",
    "        new_u = old_to_new_map[u]\n",
    "        new_v = old_to_new_map[v]\n",
    "        final_edges.append(tuple(sorted((new_u, new_v))))\n",
    "        \n",
    "    final_edges.sort()\n",
    "\n",
    "    return sorted_vertices, final_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.476115Z",
     "start_time": "2026-01-07T01:01:01.468794Z"
    }
   },
   "outputs": [],
   "source": [
    "def manual_delaunay_generator(width=10, height=10, num_points=15):\n",
    "    # generates random points and edges\n",
    "    vertices = []\n",
    "    # adding corners\n",
    "    vertices.extend([(0.0, 0.0), (float(width), 0.0), (0.0, float(height)), (float(width), float(height))])\n",
    "    \n",
    "    # random points\n",
    "    for _ in range(num_points):\n",
    "        x = random.uniform(0.1, width - 0.1)\n",
    "        y = random.uniform(0.1, height - 0.1)\n",
    "        vertices.append((x, y))\n",
    "\n",
    "    # triangulization\n",
    "    n = len(vertices)\n",
    "    edges = set()\n",
    "\n",
    "    # checking every tree points\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            for k in range(j + 1, n):\n",
    "                x1, y1 = vertices[i]\n",
    "                x2, y2 = vertices[j]\n",
    "                x3, y3 = vertices[k]\n",
    "\n",
    "                # det\n",
    "                D = 2 * (x1 * (y2 - y3) + x2 * (y3 - y1) + x3 * (y1 - y2))\n",
    "                \n",
    "                # if points are collinear\n",
    "                if abs(D) < 1e-5: continue\n",
    "                \n",
    "                # srodek okregu opisanego\n",
    "                Ux = ((x1**2 + y1**2) * (y2 - y3) + (x2**2 + y2**2) * (y3 - y1) + (x3**2 + y3**2) * (y1 - y2)) / D\n",
    "                Uy = ((x1**2 + y1**2) * (x3 - x2) + (x2**2 + y2**2) * (x1 - x3) + (x3**2 + y3**2) * (x2 - x1)) / D\n",
    "                \n",
    "                r_sq = (Ux - x1)**2 + (Uy - y1)**2\n",
    "                center = (Ux, Uy)\n",
    "                \n",
    "                # Warunek Delaunaya\n",
    "                is_valid = True\n",
    "                for m in range(n):\n",
    "                    if m == i or m == j or m == k: continue\n",
    "                    dist_sq = (vertices[m][0] - center[0])**2 + (vertices[m][1] - center[1])**2\n",
    "                    \n",
    "                    if dist_sq < r_sq - 1e-5:\n",
    "                        is_valid = False\n",
    "                        break\n",
    "                \n",
    "                if is_valid:\n",
    "                    edges.add(tuple(sorted((i, j))))\n",
    "                    edges.add(tuple(sorted((j, k))))\n",
    "                    edges.add(tuple(sorted((k, i))))\n",
    "\n",
    "    edge_list = list(edges)\n",
    "\n",
    "    # fallback\n",
    "    if len(edge_list) == 0:\n",
    "        print(\"  [INFO] Triangulacja zwróciła 0 krawędzi. Używam fallbacku.\")\n",
    "        for i in range(len(vertices) - 1):\n",
    "            edge_list.append((i, i+1))\n",
    "        # close loop\n",
    "        edge_list.append((len(vertices)-1, 0))\n",
    "\n",
    "    return vertices, edge_list, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Przykłady i Testy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.485580Z",
     "start_time": "2026-01-07T01:01:01.481802Z"
    }
   },
   "outputs": [],
   "source": [
    "Polygons = [\n",
    "    [\n",
    "        [ [(np.float64(94.6774193548387), np.float64(6.3311688311688314)), (np.float64(10.64516129032258), np.float64(9.090909090909093)), (np.float64(32.74193548387096), np.float64(22.4025974025974)), (np.float64(64.03225806451613), np.float64(36.36363636363637)), (np.float64(38.38709677419355), np.float64(64.6103896103896)), (np.float64(72.09677419354838), np.float64(75.97402597402598)), (np.float64(15.806451612903224), np.float64(85.55194805194805)), (np.float64(91.29032258064517), np.float64(87.33766233766235))]],\n",
    "        [(6, 7), (0, 7), (0, 1), (1, 6), (4, 6), (2, 4), (1, 2), (2, 5), (4, 5), (5, 7), (0, 5), (0, 2), (0, 3), (2, 3), (3, 5)]\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.500182Z",
     "start_time": "2026-01-07T01:01:01.492721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wystąpił błąd podczas wizualizacji: pop from empty list\n"
     ]
    }
   ],
   "source": [
    "\n",
    "POINT = (20, 20)\n",
    "\n",
    "P =  [(np.float64(18.709677419354836), np.float64(6.493506493506494)), (np.float64(84.6774193548387), np.float64(14.61038961038961)), (np.float64(68.70967741935485), np.float64(31.33116883116883)), (np.float64(41.77419354838709), np.float64(48.37662337662338)), (np.float64(53.70967741935485), np.float64(77.1103896103896)), (np.float64(18.548387096774196), np.float64(83.11688311688312)), (np.float64(84.35483870967742), np.float64(89.77272727272728))]\n",
    "E =  [(5, 6), (1, 6), (0, 1), (0, 5), (0, 3), (3, 5), (3, 4), (4, 5), (4, 6), (2, 4), (2, 6), (1, 2), (2, 3), (0, 2)]\n",
    "Pol =  [[(np.float64(18.548387096774196), np.float64(83.11688311688312)), (np.float64(84.35483870967742), np.float64(89.77272727272728)), (np.float64(84.6774193548387), np.float64(14.61038961038961)), (np.float64(18.709677419354836), np.float64(6.493506493506494))], [(np.float64(18.709677419354836), np.float64(6.493506493506494)), (np.float64(41.77419354838709), np.float64(48.37662337662338)), (np.float64(18.548387096774196), np.float64(83.11688311688312))], [(np.float64(41.77419354838709), np.float64(48.37662337662338)), (np.float64(53.70967741935485), np.float64(77.1103896103896)), (np.float64(18.548387096774196), np.float64(83.11688311688312))], [(np.float64(53.70967741935485), np.float64(77.1103896103896)), (np.float64(18.548387096774196), np.float64(83.11688311688312)), (np.float64(84.35483870967742), np.float64(89.77272727272728))], [(np.float64(53.70967741935485), np.float64(77.1103896103896)), (np.float64(68.70967741935485), np.float64(31.33116883116883)), (np.float64(84.35483870967742), np.float64(89.77272727272728))], [(np.float64(68.70967741935485), np.float64(31.33116883116883)), (np.float64(84.6774193548387), np.float64(14.61038961038961)), (np.float64(84.35483870967742), np.float64(89.77272727272728))], [(np.float64(41.77419354838709), np.float64(48.37662337662338)), (np.float64(68.70967741935485), np.float64(31.33116883116883)), (np.float64(53.70967741935485), np.float64(77.1103896103896))], [(np.float64(18.709677419354836), np.float64(6.493506493506494)), (np.float64(68.70967741935485), np.float64(31.33116883116883)), (np.float64(41.77419354838709), np.float64(48.37662337662338))]]\n",
    "Pol =  [[(np.float64(36.935483870967744), np.float64(82.79220779220779)), (np.float64(17.580645161290324), np.float64(29.383116883116884)), (np.float64(68.54838709677419), np.float64(26.13636363636364))], [(np.float64(36.935483870967744), np.float64(82.79220779220779)), (np.float64(73.87096774193549), np.float64(94.48051948051949)), (np.float64(68.54838709677419), np.float64(26.13636363636364))], [(np.float64(68.54838709677419), np.float64(26.13636363636364)), (np.float64(59.83870967741936), np.float64(8.116883116883116)), (np.float64(17.580645161290324), np.float64(29.383116883116884))], [(np.float64(17.580645161290324), np.float64(29.383116883116884)), (np.float64(52.25806451612904), np.float64(34.41558441558442)), (np.float64(43.70967741935483), np.float64(57.46753246753247)), (np.float64(30.64516129032258), np.float64(52.75974025974026))]]\n",
    "P, E = process_polygons_to_mesh(Pol)\n",
    "\n",
    "# Próba wizualizacji dla przetworzonych danych\n",
    "try:\n",
    "    vis_, e_ = separators_method_point_location_algorithm_visualiser(P, E, POINT)\n",
    "    vis_.show()\n",
    "    vis = animate_point_location(P, E, POINT)\n",
    "    vis.save_gif(\"gif\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Wystąpił błąd podczas wizualizacji: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:07.909025Z",
     "start_time": "2026-01-07T01:01:01.512145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam generowanie animacji...\n",
      "\n",
      "--- Przetwarzanie scenariusza 0: Nieregularny (Własna Triangulacja) ---\n",
      "    [BŁĄD]: pop from empty list\n",
      "    [BŁĄD]: pop from empty list\n",
      "\n",
      "--- Przetwarzanie scenariusza 1: Siatka 3x3 (Kwadraty) ---\n",
      "    -> Zapisano: gif\\scenariusz_01_punkt_0.gif\n",
      "    -> Zapisano: gif\\scenariusz_01_punkt_1.gif\n",
      "\n",
      "--- Przetwarzanie scenariusza 2: Siatka 4x2 (Równoległoboki) ---\n",
      "    -> Zapisano: gif\\scenariusz_02_punkt_0.gif\n",
      "    -> Zapisano: gif\\scenariusz_02_punkt_1.gif\n",
      "\n",
      "--- Przetwarzanie scenariusza 3: Siatka 2x5 (Trójkąty) ---\n",
      "    -> Zapisano: gif\\scenariusz_03_punkt_0.gif\n",
      "    -> Zapisano: gif\\scenariusz_03_punkt_1.gif\n"
     ]
    }
   ],
   "source": [
    "def generate_tri_grid(width, height):\n",
    "    vertices = []\n",
    "    edges = []\n",
    "    for y in range(height + 1):\n",
    "        for x in range(width + 1):\n",
    "            vertices.append((float(x), float(y)))\n",
    "    def get_idx(x, y):\n",
    "        return y * (width + 1) + x\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            u = get_idx(x, y)\n",
    "            right = get_idx(x + 1, y)\n",
    "            top = get_idx(x, y + 1)\n",
    "            top_right = get_idx(x + 1, y + 1)\n",
    "            edges.append((u, right))\n",
    "            edges.append((u, top))\n",
    "            edges.append((right, top_right))\n",
    "            edges.append((top, top_right))\n",
    "            edges.append((u, top_right))\n",
    "    unique_edges = set()\n",
    "    for u, v in edges:\n",
    "        if u < v: unique_edges.add((u, v))\n",
    "        else: unique_edges.add((v, u))\n",
    "    return vertices, list(unique_edges), 0\n",
    "\n",
    "def generate_quad_grid(width, height, skew=0.0):\n",
    "    vertices = []\n",
    "    edges = []\n",
    "    for y in range(height + 1):\n",
    "        shift = y * skew\n",
    "        for x in range(width + 1):\n",
    "            vertices.append((float(x + shift), float(y)))\n",
    "    def get_idx(x, y):\n",
    "        return y * (width + 1) + x\n",
    "    for y in range(height + 1):\n",
    "        for x in range(width):\n",
    "            u = get_idx(x, y)\n",
    "            v = get_idx(x + 1, y)\n",
    "            edges.append((u, v))\n",
    "    for x in range(width + 1):\n",
    "        for y in range(height):\n",
    "            u = get_idx(x, y)\n",
    "            v = get_idx(x, y + 1)\n",
    "            edges.append((u, v))\n",
    "    unique_edges = set()\n",
    "    for u, v in edges:\n",
    "        if u < v: unique_edges.add((u, v))\n",
    "        else: unique_edges.add((v, u))\n",
    "    return vertices, list(unique_edges), skew\n",
    "\n",
    "# Scenariusze Testowe\n",
    "scenarios = [\n",
    "    {\"gen\": lambda: manual_delaunay_generator(width=10, height=10, num_points=30), \n",
    "        \"dims\": (10, 10),\n",
    "        \"desc\": \"Nieregularny (Własna Triangulacja)\"},\n",
    "    {\"gen\": lambda: generate_quad_grid(3, 3, skew=0.0), \"dims\": (3, 3), \"desc\": \"Siatka 3x3 (Kwadraty)\"},\n",
    "    {\"gen\": lambda: generate_quad_grid(4, 2, skew=0.5), \"dims\": (4, 2), \"desc\": \"Siatka 4x2 (Równoległoboki)\"},\n",
    "    {\"gen\": lambda: generate_tri_grid(2, 5), \"dims\": (2, 5), \"desc\": \"Siatka 2x5 (Trójkąty)\"},\n",
    "]\n",
    "\n",
    "output_folder = \"gif\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "print(\"Rozpoczynam generowanie animacji...\")\n",
    "for s_idx, scen in enumerate(scenarios):\n",
    "    desc = scen[\"desc\"]\n",
    "    w, h = scen[\"dims\"]\n",
    "    print(f\"\\n--- Przetwarzanie scenariusza {s_idx}: {desc} ---\")\n",
    "    vertices, edges, skew = scen[\"gen\"]()\n",
    "    points_to_check = []\n",
    "    for _ in range(2):\n",
    "        py = random.uniform(0, h)\n",
    "        shift_at_y = py * skew \n",
    "        px = random.uniform(0 + shift_at_y, w + shift_at_y)\n",
    "        points_to_check.append((px, py))\n",
    "        \n",
    "    for p_idx, point in enumerate(points_to_check):\n",
    "        try:\n",
    "            vis_anim = animate_point_location(vertices, edges, point)\n",
    "            if vis_anim:\n",
    "                filename = f\"scenariusz_{s_idx:02d}_punkt_{p_idx}.gif\"\n",
    "                full_path = os.path.join(output_folder, filename)\n",
    "                vis_anim.save_gif(full_path)\n",
    "                print(f\"    -> Zapisano: {full_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    [BŁĄD]: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dodatki (Analiza i Input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:07.928493Z",
     "start_time": "2026-01-07T01:01:07.921550Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_large_procedural_graph(rows, cols):\n",
    "    \"\"\"\n",
    "    Generuje duży, poprawny graf planarny w formie siatki trójkątów.\n",
    "    Zwraca (vertices, edges).\n",
    "\n",
    "    Liczba wierzchołków V = rows * cols\n",
    "    \"\"\"\n",
    "    vertices = []\n",
    "    edges = []\n",
    "\n",
    "    # 1. Generowanie wierzchołków (V)\n",
    "    # Dodajemy mały losowy 'jitter', żeby punkty nie były idealnie w linii (bardziej realistyczne)\n",
    "    for y in range(rows):\n",
    "        for x in range(cols):\n",
    "            jitter_x = random.uniform(-0.2, 0.2)\n",
    "            jitter_y = random.uniform(-0.2, 0.2)\n",
    "            vertices.append((float(x) + jitter_x, float(y) + jitter_y))\n",
    "\n",
    "    # pomoc do pobierania indeksu w liście jednowymiarowej\n",
    "    def get_idx(c, r):\n",
    "        return r * cols + c\n",
    "\n",
    "    # 2. Generowanie krawędzi (E) - łączenie z sąsiadami (prawo, góra, góra-prawo)\n",
    "    for r in range(rows - 1):\n",
    "        for c in range(cols - 1):\n",
    "            curr = get_idx(c, r)\n",
    "            right = get_idx(c + 1, r)\n",
    "            top = get_idx(c, r + 1)\n",
    "            top_right = get_idx(c + 1, r + 1) # Przekątna\n",
    "\n",
    "            # Krawędź pozioma\n",
    "            edges.append((curr, right))\n",
    "            # Krawędź pionowa\n",
    "            edges.append((curr, top))\n",
    "            # Krawędź ukośna (tworzy trójkąty)\n",
    "            edges.append((curr, top_right))\n",
    "\n",
    "            # Domknięcie krawędzi na brzegach siatki (dla estetyki, opcjonalne)\n",
    "            if c == cols - 2: # Ostatnia kolumna, krawędzie pionowe\n",
    "                edges.append((right, top_right))\n",
    "\n",
    "        # Ostatni rząd, krawędzie poziome\n",
    "        for c in range(cols - 1):\n",
    "            bottom_last = get_idx(c, rows - 1)\n",
    "            bottom_right_last = get_idx(c + 1, rows - 1)\n",
    "            edges.append((bottom_last, bottom_right_last))\n",
    "\n",
    "    return vertices, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:02:57.205997Z",
     "start_time": "2026-01-07T01:02:22.053697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam benchmark dla: TriGrid\n",
      "  Zakończono dla V=121\n",
      "  Zakończono dla V=2601\n",
      "  Zakończono dla V=10201\n",
      "  Zakończono dla V=22801\n",
      "  Zakończono dla V=40401\n",
      "  Zakończono dla V=160801\n",
      "Rozpoczynam benchmark dla: QuadGrid\n",
      "  Zakończono dla V=121\n",
      "  Zakończono dla V=2601\n",
      "  Zakończono dla V=10201\n",
      "  Zakończono dla V=22801\n",
      "  Zakończono dla V=40401\n",
      "  Zakończono dla V=160801\n",
      "\n",
      "Wyniki końcowe:\n",
      "   Typ Grafu  Liczba V  Liczba E  Czas Budowy [s]  Czas Zapytania [s]\n",
      "0    TriGrid       121       320         0.169191            0.000014\n",
      "1    TriGrid      2601      7600         0.057865            0.000040\n",
      "2    TriGrid     10201     30200         4.547816            0.000024\n",
      "3    TriGrid     22801     67800         0.951596            0.000030\n",
      "4    TriGrid     40401    120400         1.498787            0.000038\n",
      "5    TriGrid    160801    480800         7.008073            0.000064\n",
      "6   QuadGrid       121       220         0.004012            0.000008\n",
      "7   QuadGrid      2601      5100         0.138088            0.000012\n",
      "8   QuadGrid     10201     20200         0.134418            0.000021\n",
      "9   QuadGrid     22801     45300         1.312925            0.000030\n",
      "10  QuadGrid     40401     80400         1.068172            0.000043\n",
      "11  QuadGrid    160801    320800         4.516106            0.000050\n"
     ]
    }
   ],
   "source": [
    "grid_sizes = [10, 50, 100, 150, 200, 400] #, 600]\n",
    "result_list = []\n",
    "ReportsDir = \"Reports/\"\n",
    "\n",
    "test_configs = [\n",
    "    ('TriGrid', generate_tri_grid),\n",
    "    ('QuadGrid', generate_quad_grid)\n",
    "]\n",
    "\n",
    "for type_name, generator_func in test_configs:\n",
    "    print(f\"Rozpoczynam benchmark dla: {type_name}\")\n",
    "\n",
    "    for N in grid_sizes:\n",
    "        # 1. Generowanie danych (używamy generatora z obecnej konfiguracji)\n",
    "        # Zakładam, że oba generatory zwracają (vertices, edges, _)\n",
    "        vertices, edges, _ = generator_func(N, N)\n",
    "        setNum = len(vertices)\n",
    "\n",
    "        # --- POMIAR CZASU BUDOWY ---\n",
    "        t0 = time()\n",
    "        try:\n",
    "            graph = build_graph(vertices, edges)\n",
    "            compute_planar_weights(graph)\n",
    "            separators = generate_monotone_chains(graph)\n",
    "            bst_root = create_search_structure(separators)\n",
    "            build_time = time() - t0\n",
    "\n",
    "            # --- POMIAR CZASU ZAPYTANIA ---\n",
    "            query_count = 100\n",
    "            test_points = [(random.uniform(0, N), random.uniform(0, N)) for _ in range(query_count)]\n",
    "\n",
    "            t1 = time()\n",
    "            for p in test_points:\n",
    "                # query_search_tree używa bst_root i skrajnych separatorów\n",
    "                query_search_tree(p, bst_root, closest_left=separators[0], closest_right=separators[-1])\n",
    "            query_time_total = time() - t1\n",
    "            avg_query_time = query_time_total / query_count\n",
    "\n",
    "            # Dodanie do listy wyników\n",
    "            result_list.append({\n",
    "                'Typ Grafu': type_name,\n",
    "                'Liczba V': setNum,\n",
    "                'Liczba E': len(edges),\n",
    "                'Czas Budowy [s]': build_time,\n",
    "                'Czas Zapytania [s]': avg_query_time\n",
    "            })\n",
    "            print(f\"  Zakończono dla V={setNum}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Błąd podczas przetwarzania {type_name} dla V={setNum}: {e}\")\n",
    "\n",
    "# Tworzenie DataFrame i zapis\n",
    "final_dataframe = pd.DataFrame(result_list)\n",
    "print(\"\\nWyniki końcowe:\")\n",
    "print(final_dataframe)\n",
    "\n",
    "# Zapis do CSV (nadpisze poprzedni plik lub stworzy nowy)\n",
    "if not os.path.exists(ReportsDir):\n",
    "    os.makedirs(ReportsDir)\n",
    "\n",
    "final_dataframe.to_csv(ReportsDir + 'Benchmark_Separatory_Full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:55.908226Z",
     "start_time": "2026-01-07T01:01:30.565992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Liczba V  Liczba E  Czas Budowy [s]  Czas Zapytania [s] Typ Grafu\n",
      "0       121       320         0.006279            0.000022   TriGrid\n",
      "1      2601      7600         0.071486            0.000021   TriGrid\n",
      "2     10201     30200         0.997894            0.000061   TriGrid\n",
      "3     22801     67800         0.936604            0.000052   TriGrid\n",
      "4     40401    120400         1.317816            0.000065   TriGrid\n",
      "5    160801    480800         6.653133            0.000047   TriGrid\n",
      "6    361201   1081200        16.949869            0.000052   TriGrid\n"
     ]
    }
   ],
   "source": [
    "# Lista rozmiarów siatek (NxN), dla których robimy benchmark\n",
    "grid_sizes = [10, 50, 100, 150, 200, 400 , 600 ]#, 1000 ]#, 10000]\n",
    "result_list = []\n",
    "\n",
    "ReportsDir = \"Reports/\"\n",
    "\n",
    "for N in grid_sizes:\n",
    "    # 1. Generowanie danych (Tri Grid)\n",
    "    # V = N*N, E ≈ 3*N*N\n",
    "    vertices, edges, _ = generate_tri_grid(N, N)\n",
    "    setNum = len(vertices)\n",
    "\n",
    "    # --- POMIAR CZASU BUDOWY ---\n",
    "    t0 = time()\n",
    "    graph = build_graph(vertices, edges)\n",
    "    compute_planar_weights(graph)\n",
    "    separators = generate_monotone_chains(graph)\n",
    "    bst_root = create_search_structure(separators)\n",
    "    build_time = time() - t0\n",
    "\n",
    "    # --- POMIAR CZASU ZAPYTANIA ---\n",
    "    # Wykonujemy 100 zapytań, aby uśrednić wynik dla bardzo małych czasów\n",
    "    query_count = 100\n",
    "    test_points = [(random.uniform(0, N), random.uniform(0, N)) for _ in range(query_count)]\n",
    "\n",
    "    t1 = time()\n",
    "    for p in test_points:\n",
    "        query_search_tree(p, bst_root, closest_left=separators[0], closest_right=separators[-1])\n",
    "    query_time_total = time() - t1\n",
    "    avg_query_time = query_time_total / query_count\n",
    "\n",
    "    # Dodanie do listy w Twoim stylu\n",
    "    result_list.append({\n",
    "        'Liczba V': setNum,\n",
    "        'Liczba E': len(edges),\n",
    "        'Czas Budowy [s]': build_time,\n",
    "        'Czas Zapytania [s]': avg_query_time,\n",
    "        'Typ Grafu': 'TriGrid'\n",
    "    })\n",
    "\n",
    "# Tworzenie DataFrame i zapis\n",
    "final_dataframe = pd.DataFrame(result_list)\n",
    "print(final_dataframe)\n",
    "\n",
    "# Zapis do CSV\n",
    "final_dataframe.to_csv(ReportsDir + 'Benchmark_Separatory.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
