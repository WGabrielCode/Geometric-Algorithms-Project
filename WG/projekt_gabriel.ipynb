{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt: Lokalizacja punktu w przestrzeni dwuwymiarowej – Metoda Separatorów\n",
    "**Autor:** Gabriel\n",
    "**Przedmiot:** Algorytmy Geometryczne\n",
    "\n",
    "## 1. Wstęp Teoretyczny\n",
    "[cite_start]Problem lokalizacji punktu polega na znalezieniu regionu $R_i$ w podziale płaszczyzny, który zawiera dany punkt zapytania $p$[cite: 13]. W tym projekcie prezentujemy **Metodę Łańcuchów (Chain Method)**, znaną również jako metoda separatorów.\n",
    "\n",
    "### Główne założenia metody:\n",
    "1.  **Monotoniczność:** Podział płaszczyzny składa się z obszarów monotonicznych. [cite_start]Jeśli obszary nie są monotoniczne, wymagana jest regularyzacja (np. triangulacja)[cite: 104].\n",
    "2.  [cite_start]**Separatory (Łańcuchy):** Konstruujemy zbiór łańcuchów monotonicznych, które uporządkowują obszary od lewej do prawej[cite: 14].\n",
    "\n",
    "[cite_start]Struktura danych to drzewo binarne, gdzie węzły reprezentują łańcuchy, a liście reprezentują regiony[cite: 30]. Zapytanie o punkt polega na dyskryminacji (porównaniu) położenia punktu względem kolejnych łańcuchów w drzewie, co pozwala na osiągnięcie logarytmicznego czasu zapytania.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.376357Z",
     "start_time": "2026-01-07T01:01:01.371765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List , Tuple , Optional , Union , Any\n",
    "from functools import cmp_to_key\n",
    "from data import raw\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bitalg.visualizer.main import Visualizer\n",
    "from time import time\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.389787Z",
     "start_time": "2026-01-07T01:01:01.384660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TOLERANCE = 1e-24\n",
    "\n",
    "# Data Structures\n",
    "\n",
    "class Vertex:\n",
    "    def __init__(self, x_coord: float, y_coord: float):\n",
    "        self.x = x_coord\n",
    "        self.y = y_coord\n",
    "        self.adj_out: List[Tuple['Vertex', int]] = []\n",
    "        self.adj_in: List[Tuple['Vertex', int]] = []\n",
    "        self.accumulated_weight_in = 0\n",
    "        self.accumulated_weight_out = 0\n",
    "\n",
    "    @property\n",
    "    def coords(self) -> Tuple[float, float]:\n",
    "        return self.x, self.y\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"V({self.x:.2f}, {self.y:.2f})\"\n",
    "\n",
    "class MonotoneChain:\n",
    "    def __init__(self):\n",
    "        self.path_vertices: List[Tuple[float, float]] = []\n",
    "        self.path_segments: List[Tuple[Tuple[float, float], Tuple[float, float]]] = []\n",
    "\n",
    "    def add_node(self, coords: Tuple[float, float]):\n",
    "        self.path_vertices.append(coords)\n",
    "\n",
    "    def add_segment(self, start: Tuple[float, float], end: Tuple[float, float]):\n",
    "        self.path_segments.append((start, end))\n",
    "\n",
    "class SearchTreeNode:\n",
    "    def __init__(self, segments: List, chain_ref: MonotoneChain, parent: Optional['SearchTreeNode'] = None):\n",
    "        self.left_child: Optional[SearchTreeNode] = None\n",
    "        self.right_child: Optional[SearchTreeNode] = None\n",
    "        self.parent = parent\n",
    "        self.segments = segments\n",
    "        self.chain_ref = chain_ref"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Przetwarzanie Grafu i Wagi Planarne\n",
    "Aby zbudować drzewo łańcuchów, musimy najpierw odpowiednio skierować krawędzie i nadać im wagi. Algorytm wykonuje dwa przejścia:\n",
    "1.  **Forward pass:** Propagacja wag z dołu do góry.\n",
    "2.  **Backward pass:** Korekta wag z góry na dół.\n",
    "\n",
    "[cite_start]Celem jest ustalenie przepływu tak, aby każdy łańcuch mógł zostać wyodrębniony jako ścieżka monotoniczna od źródła do ujścia grafu[cite: 33]."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.403100Z",
     "start_time": "2026-01-07T01:01:01.395598Z"
    }
   },
   "source": [
    "# Geometry Utils\n",
    "\n",
    "def cross_product(o: Tuple[float, float], a: Tuple[float, float], b: Tuple[float, float]) -> float:\n",
    "    return (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0])\n",
    "\n",
    "# Graph Processing\n",
    "\n",
    "def build_graph(raw_vertices: List[Tuple[float, float]], raw_edges: List[Tuple[int, int]]) -> List[Vertex]:\n",
    "    graph_nodes = [Vertex(x, y) for x, y in raw_vertices]\n",
    "    for start_idx, end_idx in raw_edges:\n",
    "        # Ensure edges point upwards (or rightwards for equal Y) to maintain DAG property\n",
    "        u, v = sorted((start_idx, end_idx))\n",
    "        node_u = graph_nodes[u]\n",
    "        node_v = graph_nodes[v]\n",
    "        node_u.adj_out.append((node_v, 1))\n",
    "        node_v.adj_in.append((node_u, 1))\n",
    "    return graph_nodes\n",
    "\n",
    "def compute_planar_weights(graph: List[Vertex]):\n",
    "    for node in graph:\n",
    "        center = node.coords\n",
    "        \n",
    "        # Sort edges angularly to identify \"leftmost\" and \"rightmost\" paths\n",
    "        def angular_comparator(edge1, edge2):\n",
    "            p1 = edge1[0].coords\n",
    "            p2 = edge2[0].coords\n",
    "            cp = cross_product(center, p1, p2)\n",
    "            if math.isclose(cp, 0, abs_tol=TOLERANCE): return 0\n",
    "            return -1 if cp > 0 else 1\n",
    "\n",
    "        node.adj_out.sort(key=cmp_to_key(angular_comparator))\n",
    "        node.adj_in.sort(key=cmp_to_key(lambda a, b: -1 * angular_comparator(a, b)))\n",
    "\n",
    "    # Forward pass: Propagate weights from bottom to top\n",
    "    for i in range(1, len(graph) - 1):\n",
    "        v = graph[i]\n",
    "        v.accumulated_weight_in = sum(w for _, w in v.adj_in)\n",
    "        v.accumulated_weight_out = len(v.adj_out)\n",
    "        \n",
    "        # if input flow > output flow, push excess to leftmost outgoing edge\n",
    "        if v.accumulated_weight_in > v.accumulated_weight_out:\n",
    "            target_node, current_w = v.adj_out.pop(0)\n",
    "            new_weight = current_w + v.accumulated_weight_in - v.accumulated_weight_out\n",
    "            v.adj_out.insert(0, (target_node, new_weight))\n",
    "            \n",
    "            # Update the corresponding incoming edge at the target node\n",
    "            for idx, (neighbor, w) in enumerate(target_node.adj_in):\n",
    "                if neighbor == v:\n",
    "                    target_node.adj_in[idx] = (v, new_weight)\n",
    "                    break\n",
    "\n",
    "    # Backward pass: Propagate weights from top to bottom\n",
    "    for i in range(len(graph) - 2, 0, -1):\n",
    "        v = graph[i]\n",
    "        v.accumulated_weight_in = sum(w for _, w in v.adj_in)\n",
    "        v.accumulated_weight_out = sum(w for _, w in v.adj_out)\n",
    "        \n",
    "        # If output flow > input flow, pull excess from leftmost incoming edge\n",
    "        if v.accumulated_weight_out > v.accumulated_weight_in:\n",
    "            source_node, current_w = v.adj_in.pop(0)\n",
    "            new_weight = current_w + v.accumulated_weight_out - v.accumulated_weight_in\n",
    "            v.adj_in.insert(0, (source_node, new_weight))\n",
    "            \n",
    "            for idx, (neighbor, w) in enumerate(source_node.adj_out):\n",
    "                if neighbor == v:\n",
    "                    source_node.adj_out[idx] = (v, new_weight)\n",
    "                    break"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generowanie Łańcuchów Monotonicznych i Struktura Wyszukiwania\n",
    "Algorytm zachłannie buduje łańcuchy, \"konsumując\" wagi krawędzi. Powstałe łańcuchy są następnie organizowane w zbalansowane drzewo poszukiwań binarnego (BST).\n",
    "\n",
    "* **Liście drzewa:** Odpowiadają regionom.\n",
    "[cite_start]* **Węzły wewnętrzne:** Odpowiadają łańcuchom (separatorom)[cite: 31].\n",
    "Drzewo to pozwala na szybkie określenie, po której stronie separatora znajduje się punkt."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.414740Z",
     "start_time": "2026-01-07T01:01:01.408825Z"
    }
   },
   "source": [
    "def generate_monotone_chains(graph: List[Vertex]) -> List[MonotoneChain]:\n",
    "    source_node = graph[0]\n",
    "    total_chains = sum(w for _, w in source_node.adj_out)\n",
    "    chains = [MonotoneChain() for _ in range(total_chains)]\n",
    "    \n",
    "    for chain in chains:\n",
    "        current_v = source_node\n",
    "        \n",
    "        # Traverse graph greedily consuming edge weights\n",
    "        while current_v.adj_out:\n",
    "            chain.add_node(current_v.coords)\n",
    "            chosen_idx = -1\n",
    "            \n",
    "            # Pick the rightmost available edge (non-zero weight)\n",
    "            for i in range(len(current_v.adj_out) - 1, -1, -1):\n",
    "                neighbor, weight = current_v.adj_out[i]\n",
    "                if weight > 0:\n",
    "                    chosen_idx = i\n",
    "                    break\n",
    "            if chosen_idx == -1: break\n",
    "            \n",
    "            next_v, w = current_v.adj_out[chosen_idx]\n",
    "            current_v.adj_out[chosen_idx] = (next_v, w - 1) # Decrease capacity\n",
    "            current_v = next_v\n",
    "            \n",
    "        chain.add_node(current_v.coords)\n",
    "        \n",
    "        verts = chain.path_vertices\n",
    "        for k in range(len(verts) - 1):\n",
    "            chain.add_segment(verts[k], verts[k+1])\n",
    "    return chains\n",
    "\n",
    "def create_search_structure(chains: List[MonotoneChain], parent: Optional[SearchTreeNode] = None) -> Optional[SearchTreeNode]:\n",
    "    if not chains: return None\n",
    "    mid_idx = len(chains) // 2\n",
    "    median_chain = chains[mid_idx]\n",
    "    \n",
    "    node = SearchTreeNode(median_chain.path_segments, median_chain, parent)\n",
    "    node.left_child = create_search_structure(chains[:mid_idx], node)\n",
    "    node.right_child = create_search_structure(chains[mid_idx + 1:], node)\n",
    "    return node"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logika Zapytania (Point Location)\n",
    "Dla zadanego punktu $p$ algorytm schodzi w dół drzewa. W każdym węźle sprawdzamy relację punktu względem separatora:\n",
    "* Jeśli punkt jest na lewo od separatora -> idziemy do lewego dziecka.\n",
    "[cite_start]* Jeśli punkt jest na prawo od separatora -> idziemy do prawego dziecka [cite: 49-50].\n",
    "\n",
    "Test relacji wykorzystuje iloczyn wektorowy (`cross_product`) oraz wyszukiwanie binarne na segmentach separatora."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.430237Z",
     "start_time": "2026-01-07T01:01:01.420187Z"
    }
   },
   "source": [
    "# Query Logic\n",
    "\n",
    "def find_position_relative_to_chain(point: Tuple[float, float], node: SearchTreeNode) -> int:\n",
    "    px, py = point\n",
    "    segments = node.segments\n",
    "    target_segment = None\n",
    "    \n",
    "    # Binary Search to find the segment covering the point's Y-coordinate\n",
    "    left_idx, right_idx = 0, len(segments) - 1\n",
    "    \n",
    "    while left_idx <= right_idx:\n",
    "        mid_idx = (left_idx + right_idx) // 2\n",
    "        p1, p2 = segments[mid_idx]\n",
    "        \n",
    "        y_min, y_max = p1[1], p2[1]\n",
    "        \n",
    "        if y_min - TOLERANCE <= py <= y_max + TOLERANCE:\n",
    "            target_segment = (p1, p2)\n",
    "            break\n",
    "        elif py < y_min:\n",
    "            right_idx = mid_idx - 1\n",
    "        else:\n",
    "            left_idx = mid_idx + 1\n",
    "            \n",
    "    if target_segment is None: \n",
    "        return 1\n",
    "    \n",
    "    cp = cross_product(target_segment[0], target_segment[1], point)\n",
    "    \n",
    "    if math.isclose(cp, 0, abs_tol=TOLERANCE):\n",
    "        # Handle collinear points: check if strictly inside segment bounds\n",
    "        min_x = min(target_segment[0][0], target_segment[1][0])\n",
    "        max_x = max(target_segment[0][0], target_segment[1][0])\n",
    "        if min_x <= px <= max_x:\n",
    "            return 0 \n",
    "        return -1 if px > target_segment[0][0] else 1\n",
    "    \n",
    "    # Return -1 for Right, 1 for Left\n",
    "    return -1 if cp < 0 else 1\n",
    "\n",
    "def query_search_tree(point: Tuple[float, float], node: Optional[SearchTreeNode], \n",
    "                     closest_left: Optional[MonotoneChain] = None,\n",
    "                     closest_right: Optional[MonotoneChain] = None) -> Union[MonotoneChain, Tuple[MonotoneChain, MonotoneChain]]:\n",
    "    if node is None:\n",
    "        return (closest_left, closest_right)\n",
    "        \n",
    "    position = find_position_relative_to_chain(point, node)\n",
    "    \n",
    "    if position == 0:\n",
    "        return node.chain_ref\n",
    "        \n",
    "    # Traverse BST based on point position relative to current separator\n",
    "    if position < 0:\n",
    "        return query_search_tree(point, node.right_child, closest_left=node.chain_ref, closest_right=closest_right)\n",
    "    else: \n",
    "        return query_search_tree(point, node.left_child, closest_left=closest_left, closest_right=node.chain_ref)\n",
    "\n",
    "def extract_region_edges(chain_a: MonotoneChain, chain_b: MonotoneChain, point: Tuple[float, float]) -> List[Tuple]:\n",
    "    if chain_a is None: return chain_b.path_segments \n",
    "    if chain_b is None: return chain_a.path_segments\n",
    "\n",
    "    verts_a = chain_a.path_vertices\n",
    "    verts_b = chain_b.path_vertices\n",
    "    \n",
    "    bubbles = []\n",
    "    i, j = 0, 0\n",
    "    last_common_a_idx = 0\n",
    "    last_common_b_idx = 0\n",
    "    \n",
    "    # Iterate through both chains to find split and merge points (\"bubbles\")\n",
    "    while i < len(verts_a) and j < len(verts_b):\n",
    "        va = verts_a[i]\n",
    "        vb = verts_b[j]\n",
    "        \n",
    "        is_same = math.isclose(va[0], vb[0], abs_tol=TOLERANCE) and math.isclose(va[1], vb[1], abs_tol=TOLERANCE)\n",
    "        \n",
    "        if is_same:\n",
    "            if i > last_common_a_idx or j > last_common_b_idx:\n",
    "                # Close the bubble and store it\n",
    "                bubble_a = verts_a[last_common_a_idx : i+1]\n",
    "                bubble_b = verts_b[last_common_b_idx : j+1]\n",
    "                bubbles.append((bubble_a, bubble_b))\n",
    "                \n",
    "            last_common_a_idx = i\n",
    "            last_common_b_idx = j\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            # Advance pointer for the geometrically lower vertex\n",
    "            if va[1] < vb[1] or (math.isclose(va[1], vb[1]) and va[0] < vb[0]):\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "                \n",
    "    py = point[1]\n",
    "    result_edges = []\n",
    "    \n",
    "    # Find which bubble contains the query point Y-coordinate\n",
    "    for path_a, path_b in bubbles:\n",
    "        min_y = min(v[1] for v in path_a + path_b)\n",
    "        max_y = max(v[1] for v in path_a + path_b)\n",
    "        \n",
    "        if min_y <= py <= max_y:\n",
    "            # Collect unique edges from both sides of the bubble\n",
    "            for k in range(len(path_a) - 1):\n",
    "                result_edges.append((path_a[k], path_a[k+1]))\n",
    "            for k in range(len(path_b) - 1):\n",
    "                edge = (path_b[k], path_b[k+1])\n",
    "                if edge not in result_edges:\n",
    "                    result_edges.append(edge)\n",
    "            if result_edges:\n",
    "                return result_edges\n",
    "\n",
    "    return result_edges\n",
    "\n",
    "# Main API\n",
    "\n",
    "def run_point_location(vertices: List[Tuple[float, float]], edges: List[Tuple[int, int]], query_point: Tuple[float, float]):\n",
    "    graph = build_graph(vertices, edges)\n",
    "    compute_planar_weights(graph)\n",
    "    separators = generate_monotone_chains(graph)\n",
    "    bst_root = create_search_structure(separators)\n",
    "    \n",
    "    result = query_search_tree(query_point, bst_root, closest_left=separators[0], closest_right=separators[-1])\n",
    "    \n",
    "    # Handle point exactly on a separator\n",
    "    if isinstance(result, MonotoneChain):\n",
    "        segments = result.path_segments\n",
    "        l, r = 0, len(segments) - 1\n",
    "        while l <= r:\n",
    "            mid = (l + r) // 2\n",
    "            seg = segments[mid]\n",
    "            if seg[0][1] <= query_point[1] <= seg[1][1]:\n",
    "                return [seg]\n",
    "            elif query_point[1] < seg[0][1]:\n",
    "                r = mid - 1\n",
    "            else:\n",
    "                l = mid + 1\n",
    "        return result.path_segments\n",
    "        \n",
    "    # Handle point inside a region\n",
    "    sep_left, sep_right = result\n",
    "    return extract_region_edges(sep_left, sep_right, query_point)"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.444313Z",
     "start_time": "2026-01-07T01:01:01.436677Z"
    }
   },
   "source": [
    "def separators_method_point_location_algorithm_visualiser(raw_vertices, raw_edges, point):\n",
    "    try:\n",
    "        from bitalg.visualizer.main import Visualizer\n",
    "    except ImportError:\n",
    "        return None, run_point_location(raw_vertices, raw_edges, point)\n",
    "\n",
    "    vis = Visualizer()\n",
    "    vis.add_point(raw_vertices, color=\"black\")\n",
    "    \n",
    "    segments = []\n",
    "    for u, v in raw_edges:\n",
    "        p1 = raw_vertices[u]\n",
    "        p2 = raw_vertices[v]\n",
    "        segments.append((p1, p2))\n",
    "    vis.add_line_segment(segments, color=\"gray\")\n",
    "    \n",
    "    found_edges = run_point_location(raw_vertices, raw_edges, point)\n",
    "    \n",
    "    vis.add_point(point, color=\"green\")\n",
    "    if found_edges:\n",
    "        vis.add_line_segment(found_edges, color=\"red\", linewidth=3)\n",
    "        \n",
    "    return vis, found_edges\n",
    "\n",
    "def animate_point_location(raw_vertices: List[Tuple[float, float]], \n",
    "                           raw_edges: List[Tuple[int, int]], \n",
    "                           query_point: Tuple[float, float]):\n",
    "    \"\"\"\n",
    "    Tworzy animację (GIF) działania algorytmu lokalizacji punktu.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from bitalg.visualizer.main import Visualizer\n",
    "    except ImportError:\n",
    "        print(\"Brak biblioteki bitalg.\")\n",
    "        return None\n",
    "\n",
    "    # 1. Budowa struktur\n",
    "    graph = build_graph(raw_vertices, raw_edges)\n",
    "    compute_planar_weights(graph)\n",
    "    separators = generate_monotone_chains(graph)\n",
    "    bst_root = create_search_structure(separators)\n",
    "    \n",
    "    # 2. Inicjalizacja wizualizatora\n",
    "    vis = Visualizer()\n",
    "    \n",
    "    # TŁO: Rysujemy cały graf na szaro (stały element)\n",
    "    vis.add_point(raw_vertices, color=\"black\", s=5)\n",
    "    \n",
    "    all_segments = []\n",
    "    for u, v in raw_edges:\n",
    "        p1 = raw_vertices[u]\n",
    "        p2 = raw_vertices[v]\n",
    "        all_segments.append((p1, p2))\n",
    "    vis.add_line_segment(all_segments, color=\"lightgray\", linewidth=1)\n",
    "    \n",
    "    # PUNKT: Szukany punkt na zielono (stały element)\n",
    "    vis.add_point([query_point], color=\"green\", s=20)\n",
    "    \n",
    "    # 3. Pętla animacji (przechodzenie przez drzewo)\n",
    "    current_node = bst_root\n",
    "    \n",
    "    while current_node is not None:\n",
    "        # A. Pokaż cały aktualny SEPARATOR (Pomarańczowy)\n",
    "        chain_segments = current_node.segments\n",
    "        # Zapisujemy ID figury, żeby ją potem usunąć\n",
    "        chain_fig = vis.add_line_segment(chain_segments, color=\"orange\", linewidth=2)\n",
    "        \n",
    "        # B. Znajdź konkretny SEGMENT (krawędź) na tym separatorze (Binary Search)\n",
    "        px, py = query_point\n",
    "        target_segment = None\n",
    "        left_idx, right_idx = 0, len(chain_segments) - 1\n",
    "        \n",
    "        while left_idx <= right_idx:\n",
    "            mid_idx = (left_idx + right_idx) // 2\n",
    "            p1, p2 = chain_segments[mid_idx]\n",
    "            y_min, y_max = p1[1], p2[1]\n",
    "            \n",
    "            if y_min - TOLERANCE <= py <= y_max + TOLERANCE:\n",
    "                target_segment = (p1, p2)\n",
    "                break\n",
    "            elif py < y_min:\n",
    "                right_idx = mid_idx - 1\n",
    "            else:\n",
    "                left_idx = mid_idx + 1\n",
    "        \n",
    "        seg_fig = None\n",
    "        position = 1 # Domyślnie prawo (fallback)\n",
    "\n",
    "        if target_segment:\n",
    "            # C. Pokaż sprawdzany SEGMENT (Niebieski, gruby)\n",
    "            seg_fig = vis.add_line_segment([target_segment], color=\"blue\", linewidth=4)\n",
    "            \n",
    "            # Oblicz stronę (logika algorytmu)\n",
    "            cp = cross_product(target_segment[0], target_segment[1], query_point)\n",
    "            if math.isclose(cp, 0, abs_tol=TOLERANCE):\n",
    "                position = 0 # Na krawędzi\n",
    "            else:\n",
    "                position = -1 if cp < 0 else 1\n",
    "        \n",
    "        # D. USUWANIE (To tworzy \"klatkę\" animacji)\n",
    "        if seg_fig:\n",
    "            vis.remove_figure(seg_fig)\n",
    "        \n",
    "        vis.remove_figure(chain_fig)\n",
    "        \n",
    "        # E. Decyzja - gdzie idziemy dalej?\n",
    "        if position == 0:\n",
    "            break # Znaleziono (na krawędzi)\n",
    "        elif position < 0:\n",
    "            current_node = current_node.right_child\n",
    "        else:\n",
    "            current_node = current_node.left_child\n",
    "\n",
    "    # 4. Finał: Pokaż wynikowy obszar na czerwono (zostaje na stałe)\n",
    "    found_edges = run_point_location(raw_vertices, raw_edges, query_point)\n",
    "    if found_edges:\n",
    "        vis.add_line_segment(found_edges, color=\"red\", linewidth=3)\n",
    "        \n",
    "    return vis"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Obsługa Dowolnych Wielokątów (Pre-processing)\n",
    "Ponieważ metoda łańcuchów wymaga regionów monotonicznych, dowolne wielokąty (w tym wklęsłe) muszą zostać poddane obróbce. Stosujemy tutaj metodę **Ear Clipping** do triangulacji wielokątów.\n",
    "\n",
    "[cite_start]Powstały graf trójkątów może być niespójny (zawierać \"wyspy\"), dlatego funkcja `patch_graph_connectivity` dodaje wirtualne krawędzie łączące, tworząc spójny graf wymagany przez algorytm[cite: 104]."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.462210Z",
     "start_time": "2026-01-07T01:01:01.450607Z"
    }
   },
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. NARZĘDZIA GEOMETRYCZNE (Czysty Python)\n",
    "# ---------------------------------------------------------\n",
    "def cross_product(o, a, b):\n",
    "    \"\"\"Iloczyn wektorowy 2D (OA x OB).\"\"\"\n",
    "    return (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0])\n",
    "\n",
    "def is_point_in_triangle(p, a, b, c):\n",
    "    \"\"\"Sprawdza czy punkt p leży wewnątrz trójkąta abc.\"\"\"\n",
    "    cp1 = cross_product(a, b, p)\n",
    "    cp2 = cross_product(b, c, p)\n",
    "    cp3 = cross_product(c, a, p)\n",
    "    # Punkt jest w środku, jeśli wszystkie iloczyny mają ten sam znak\n",
    "    has_neg = (cp1 < 0) or (cp2 < 0) or (cp3 < 0)\n",
    "    has_pos = (cp1 > 0) or (cp2 > 0) or (cp3 > 0)\n",
    "    return not (has_neg and has_pos)\n",
    "\n",
    "def is_convex(prev, curr, next_pt):\n",
    "    \"\"\"Sprawdza czy wierzchołek curr jest wypukły (zakładając kolejność CCW).\"\"\"\n",
    "    return cross_product(prev, curr, next_pt) >= 0 # >= 0 dla CCW\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ALGORYTM EAR CLIPPING (Triangulacja)\n",
    "# ---------------------------------------------------------\n",
    "def triangulate_single_polygon(poly_vertices):\n",
    "    \"\"\"\n",
    "    Dzieli pojedynczy wielokąt na trójkąty metodą Ear Clipping.\n",
    "    Zwraca listę trójek indeksów (lokalnych względem poly_vertices).\n",
    "    \"\"\"\n",
    "    n = len(poly_vertices)\n",
    "    if n < 3: return []\n",
    "    \n",
    "    # Tworzymy listę indeksów, którą będziemy \"przycinać\"\n",
    "    indices = list(range(n))\n",
    "    triangles = []\n",
    "    \n",
    "    # Zabezpieczenie przed pętlą nieskończoną\n",
    "    max_iter = 2 * n * n\n",
    "    count = 0\n",
    "    \n",
    "    while len(indices) > 3:\n",
    "        if count > max_iter:\n",
    "            print(\"Błąd triangulacji: zbyt wiele iteracji (zła topologia?)\")\n",
    "            break\n",
    "        \n",
    "        ear_found = False\n",
    "        num_current = len(indices)\n",
    "        \n",
    "        for i in range(num_current):\n",
    "            # Pobieramy 3 kolejne indeksy (cyklicznie)\n",
    "            prev_idx = indices[(i - 1) % num_current]\n",
    "            curr_idx = indices[i]\n",
    "            next_idx = indices[(i + 1) % num_current]\n",
    "            \n",
    "            p_prev = poly_vertices[prev_idx]\n",
    "            p_curr = poly_vertices[curr_idx]\n",
    "            p_next = poly_vertices[next_idx]\n",
    "            \n",
    "            # 1. Sprawdź czy kąt jest wypukły (to potencjalne ucho)\n",
    "            if cross_product(p_prev, p_curr, p_next) > 0: # > 0 dla CCW\n",
    "                \n",
    "                # 2. Sprawdź czy żaden INNY wierzchołek nie leży w tym trójkącie\n",
    "                is_ear = True\n",
    "                for k in range(num_current):\n",
    "                    test_idx = indices[k]\n",
    "                    if test_idx in (prev_idx, curr_idx, next_idx):\n",
    "                        continue\n",
    "                    \n",
    "                    if is_point_in_triangle(poly_vertices[test_idx], p_prev, p_curr, p_next):\n",
    "                        is_ear = False\n",
    "                        break\n",
    "                \n",
    "                # 3. Jeśli to ucho, odetnij je\n",
    "                if is_ear:\n",
    "                    triangles.append((prev_idx, curr_idx, next_idx))\n",
    "                    indices.pop(i)\n",
    "                    ear_found = True\n",
    "                    break\n",
    "        \n",
    "        count += 1\n",
    "        if not ear_found:\n",
    "            # Jeśli nie znaleziono ucha, wielokąt może być zdegenerowany lub CW\n",
    "            indices.pop(0) \n",
    "\n",
    "    # Dodaj ostatni trójkąt\n",
    "    if len(indices) == 3:\n",
    "        triangles.append((indices[0], indices[1], indices[2]))\n",
    "        \n",
    "    return triangles\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. PATCHING (Naprawa Grafu dla Metody Separatorów)\n",
    "# ---------------------------------------------------------\n",
    "def patch_graph_connectivity(vertices, edges):\n",
    "    \"\"\"\n",
    "    Dodaje wirtualne pionowe krawędzie, aby połączyć rozłączne wyspy\n",
    "    w jeden spójny graf (DAG) od min-y do max-y.\n",
    "    Rozwiązuje problem 'pop from empty list'.\n",
    "    \"\"\"\n",
    "    # Budujemy listę sąsiedztwa\n",
    "    adj_out = {i: [] for i in range(len(vertices))}\n",
    "    adj_in = {i: [] for i in range(len(vertices))}\n",
    "    \n",
    "    for u, v in edges:\n",
    "        p1, p2 = vertices[u], vertices[v]\n",
    "        if p1[1] < p2[1] or (p1[1] == p2[1] and p1[0] < p2[0]):\n",
    "            low, high = u, v\n",
    "        else:\n",
    "            low, high = v, u\n",
    "            \n",
    "        adj_out[low].append(high)\n",
    "        adj_in[high].append(low)\n",
    "\n",
    "    sorted_nodes = []\n",
    "    for i, (x, y) in enumerate(vertices):\n",
    "        sorted_nodes.append((i, y, x))\n",
    "    sorted_nodes.sort(key=lambda k: (k[1], k[2]))\n",
    "\n",
    "    new_edges = list(edges)\n",
    "    \n",
    "    # 1. Łączymy Lokalne Źródła (punkty bez wejścia)\n",
    "    for k in range(1, len(sorted_nodes)): \n",
    "        idx, y, x = sorted_nodes[k]\n",
    "        \n",
    "        if len(adj_in[idx]) == 0:\n",
    "            best_candidate = -1\n",
    "            min_dist = float('inf')\n",
    "            \n",
    "            for j in range(k-1, -1, -1):\n",
    "                cand_idx, cy, cx = sorted_nodes[j]\n",
    "                dist = abs(cx - x) + (y - cy)*2 \n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    best_candidate = cand_idx\n",
    "                if (y - cy) > 1000: break \n",
    "\n",
    "            if best_candidate != -1:\n",
    "                new_edges.append((best_candidate, idx))\n",
    "                adj_in[idx].append(best_candidate)\n",
    "\n",
    "    # 2. Łączymy Lokalne Ujścia (punkty bez wyjścia)\n",
    "    for k in range(len(sorted_nodes) - 2, -1, -1):\n",
    "        idx, y, x = sorted_nodes[k]\n",
    "        \n",
    "        if len(adj_out[idx]) == 0:\n",
    "            best_candidate = -1\n",
    "            min_dist = float('inf')\n",
    "            \n",
    "            for j in range(k+1, len(sorted_nodes)):\n",
    "                cand_idx, cy, cx = sorted_nodes[j]\n",
    "                dist = abs(cx - x) + (cy - y)*2\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    best_candidate = cand_idx\n",
    "                if (cy - y) > 1000: break\n",
    "\n",
    "            if best_candidate != -1:\n",
    "                new_edges.append((idx, best_candidate))\n",
    "                adj_out[idx].append(best_candidate)\n",
    "\n",
    "    return new_edges\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. GŁÓWNA FUNKCJA STERUJĄCA\n",
    "# ---------------------------------------------------------\n",
    "def process_polygons_manually(polygons_list):\n",
    "    global_vertices = []\n",
    "    triangles_indices = []\n",
    "    triangle_map = []\n",
    "    current_offset = 0\n",
    "    \n",
    "    # KROK A: Triangulacja każdego poligonu osobno\n",
    "    for p_id, poly in enumerate(polygons_list):\n",
    "        for pt in poly:\n",
    "            global_vertices.append(pt)\n",
    "        local_tris = triangulate_single_polygon(poly)\n",
    "        for (a, b, c) in local_tris:\n",
    "            g_a = a + current_offset\n",
    "            g_b = b + current_offset\n",
    "            g_c = c + current_offset\n",
    "            triangles_indices.append((g_a, g_b, g_c))\n",
    "            sorted_tri = tuple(sorted((g_a, g_b, g_c)))\n",
    "            triangle_map.append({'vertices': sorted_tri, 'poly_id': p_id})\n",
    "        current_offset += len(poly)\n",
    "\n",
    "    # KROK B: Konwersja trójkątów na unikalne krawędzie\n",
    "    edges_set = set()\n",
    "    for (a, b, c) in triangles_indices:\n",
    "        edges_set.add(tuple(sorted((a, b))))\n",
    "        edges_set.add(tuple(sorted((b, c))))\n",
    "        edges_set.add(tuple(sorted((c, a))))\n",
    "    raw_edges = list(edges_set)\n",
    "    \n",
    "    # KROK C: NAPRAWA GRAFU (Patching)\n",
    "    final_edges = patch_graph_connectivity(global_vertices, raw_edges)\n",
    "    return global_vertices, final_edges, triangle_map"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.476115Z",
     "start_time": "2026-01-07T01:01:01.468794Z"
    }
   },
   "source": [
    "def manual_delaunay_generator(width=10, height=10, num_points=15):\n",
    "    \"\"\"\n",
    "    Generuje losowe punkty i łączy je w siatkę (Delaunay).\n",
    "    Zwraca: (vertices, edges, skew)\n",
    "    \"\"\"\n",
    "    # 1. Generowanie punktów\n",
    "    vertices = []\n",
    "    # Dodaj narożniki (kluczowe dla stabilności triangulacji na brzegach)\n",
    "    vertices.extend([(0.0, 0.0), (float(width), 0.0), (0.0, float(height)), (float(width), float(height))])\n",
    "    \n",
    "    # Dodaj losowe punkty wewnątrz\n",
    "    for _ in range(num_points):\n",
    "        x = random.uniform(0.1, width - 0.1)\n",
    "        y = random.uniform(0.1, height - 0.1)\n",
    "        vertices.append((x, y))\n",
    "\n",
    "    # 2. Triangulacja (Metoda Brute-Force z poprawioną precyzją)\n",
    "    n = len(vertices)\n",
    "    edges = set()\n",
    "\n",
    "    # Sprawdzamy każdą trójkę punktów\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            for k in range(j + 1, n):\n",
    "                x1, y1 = vertices[i]\n",
    "                x2, y2 = vertices[j]\n",
    "                x3, y3 = vertices[k]\n",
    "\n",
    "                # Wyznacznik (podwójne pole trójkąta)\n",
    "                D = 2 * (x1 * (y2 - y3) + x2 * (y3 - y1) + x3 * (y1 - y2))\n",
    "                \n",
    "                # Jeśli punkty są współliniowe (lub prawie), pomiń\n",
    "                if abs(D) < 1e-5: continue\n",
    "                \n",
    "                # Środek okręgu opisanego\n",
    "                Ux = ((x1**2 + y1**2) * (y2 - y3) + (x2**2 + y2**2) * (y3 - y1) + (x3**2 + y3**2) * (y1 - y2)) / D\n",
    "                Uy = ((x1**2 + y1**2) * (x3 - x2) + (x2**2 + y2**2) * (x1 - x3) + (x3**2 + y3**2) * (x2 - x1)) / D\n",
    "                \n",
    "                r_sq = (Ux - x1)**2 + (Uy - y1)**2\n",
    "                center = (Ux, Uy)\n",
    "                \n",
    "                # Sprawdź Warunek Delaunaya\n",
    "                is_valid = True\n",
    "                for m in range(n):\n",
    "                    if m == i or m == j or m == k: continue\n",
    "                    dist_sq = (vertices[m][0] - center[0])**2 + (vertices[m][1] - center[1])**2\n",
    "                    \n",
    "                    # Zmniejszyliśmy epsilon dla większej tolerancji\n",
    "                    if dist_sq < r_sq - 1e-5:\n",
    "                        is_valid = False\n",
    "                        break\n",
    "                \n",
    "                if is_valid:\n",
    "                    edges.add(tuple(sorted((i, j))))\n",
    "                    edges.add(tuple(sorted((j, k))))\n",
    "                    edges.add(tuple(sorted((k, i))))\n",
    "\n",
    "    edge_list = list(edges)\n",
    "\n",
    "    # --- ZABEZPIECZENIE (Fallback) ---\n",
    "    if len(edge_list) == 0:\n",
    "        print(\"  [INFO] Triangulacja zwróciła 0 krawędzi. Używam fallbacku.\")\n",
    "        for i in range(len(vertices) - 1):\n",
    "            edge_list.append((i, i+1))\n",
    "        # Zamknij pętlę\n",
    "        edge_list.append((len(vertices)-1, 0))\n",
    "\n",
    "    return vertices, edge_list, 0"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Przykłady i Testy\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.485580Z",
     "start_time": "2026-01-07T01:01:01.481802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Polygons = [\n",
    "    [\n",
    "        [ [(np.float64(94.6774193548387), np.float64(6.3311688311688314)), (np.float64(10.64516129032258), np.float64(9.090909090909093)), (np.float64(32.74193548387096), np.float64(22.4025974025974)), (np.float64(64.03225806451613), np.float64(36.36363636363637)), (np.float64(38.38709677419355), np.float64(64.6103896103896)), (np.float64(72.09677419354838), np.float64(75.97402597402598)), (np.float64(15.806451612903224), np.float64(85.55194805194805)), (np.float64(91.29032258064517), np.float64(87.33766233766235))]],\n",
    "        [(6, 7), (0, 7), (0, 1), (1, 6), (4, 6), (2, 4), (1, 2), (2, 5), (4, 5), (5, 7), (0, 5), (0, 2), (0, 3), (2, 3), (3, 5)]\n",
    "    ],\n",
    "    [\n",
    "\n",
    "    ]\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:01.500182Z",
     "start_time": "2026-01-07T01:01:01.492721Z"
    }
   },
   "source": [
    "P =  [(np.float64(94.6774193548387), np.float64(6.3311688311688314)), (np.float64(10.64516129032258), np.float64(9.090909090909093)), (np.float64(32.74193548387096), np.float64(22.4025974025974)), (np.float64(64.03225806451613), np.float64(36.36363636363637)), (np.float64(38.38709677419355), np.float64(64.6103896103896)), (np.float64(72.09677419354838), np.float64(75.97402597402598)), (np.float64(15.806451612903224), np.float64(85.55194805194805)), (np.float64(91.29032258064517), np.float64(87.33766233766235))]\n",
    "E =  [(6, 7), (0, 7), (0, 1), (1, 6), (4, 6), (2, 4), (1, 2), (2, 5), (4, 5), (5, 7), (0, 5), (0, 2), (0, 3), (2, 3), (3, 5)]\n",
    "POINT = (45, 70)\n",
    "Pol = [[(np.float64(20.161290322580644), np.float64(82.46753246753246)), (np.float64(86.12903225806451), np.float64(85.55194805194805)), (np.float64(74.19354838709677), np.float64(13.149350649350652)), (np.float64(13.387096774193548), np.float64(16.558441558441558))], [(np.float64(45.64516129032258), np.float64(49.837662337662344)), (np.float64(86.12903225806451), np.float64(85.55194805194805)), (np.float64(74.19354838709677), np.float64(13.149350649350652))], [(np.float64(45.64516129032258), np.float64(49.837662337662344)), (np.float64(29.999999999999996), np.float64(28.24675324675325)), (np.float64(20.161290322580644), np.float64(82.46753246753246))], [(np.float64(20.161290322580644), np.float64(82.46753246753246)), (np.float64(50.483870967741936), np.float64(95.12987012987014)), (np.float64(86.12903225806451), np.float64(85.55194805194805))], [(np.float64(86.12903225806451), np.float64(85.55194805194805)), (np.float64(96.29032258064517), np.float64(90.42207792207793)), (np.float64(74.19354838709677), np.float64(13.149350649350652))], [(np.float64(13.387096774193548), np.float64(16.558441558441558)), (np.float64(21.290322580645164), np.float64(28.409090909090907)), (np.float64(25.322580645161292), np.float64(20.454545454545453))], [(np.float64(25.322580645161292), np.float64(20.454545454545453)), (np.float64(13.387096774193548), np.float64(16.558441558441558)), (np.float64(74.19354838709677), np.float64(13.149350649350652))]]\n",
    "P, E, _ = process_polygons_manually(Pol)\n",
    "\n",
    "# Próba wizualizacji dla przetworzonych danych\n",
    "try:\n",
    "    vis_, e_ = separators_method_point_location_algorithm_visualiser(P, E, POINT)\n",
    "    vis_.show()\n",
    "except Exception as e:\n",
    "    print(f\"Wystąpił błąd podczas wizualizacji: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wystąpił błąd podczas wizualizacji: pop from empty list\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:07.909025Z",
     "start_time": "2026-01-07T01:01:01.512145Z"
    }
   },
   "source": [
    "def generate_tri_grid(width, height):\n",
    "    vertices = []\n",
    "    edges = []\n",
    "    for y in range(height + 1):\n",
    "        for x in range(width + 1):\n",
    "            vertices.append((float(x), float(y)))\n",
    "    def get_idx(x, y):\n",
    "        return y * (width + 1) + x\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            u = get_idx(x, y)\n",
    "            right = get_idx(x + 1, y)\n",
    "            top = get_idx(x, y + 1)\n",
    "            top_right = get_idx(x + 1, y + 1)\n",
    "            edges.append((u, right))\n",
    "            edges.append((u, top))\n",
    "            edges.append((right, top_right))\n",
    "            edges.append((top, top_right))\n",
    "            edges.append((u, top_right))\n",
    "    unique_edges = set()\n",
    "    for u, v in edges:\n",
    "        if u < v: unique_edges.add((u, v))\n",
    "        else: unique_edges.add((v, u))\n",
    "    return vertices, list(unique_edges), 0\n",
    "\n",
    "def generate_quad_grid(width, height, skew=0.0):\n",
    "    vertices = []\n",
    "    edges = []\n",
    "    for y in range(height + 1):\n",
    "        shift = y * skew\n",
    "        for x in range(width + 1):\n",
    "            vertices.append((float(x + shift), float(y)))\n",
    "    def get_idx(x, y):\n",
    "        return y * (width + 1) + x\n",
    "    for y in range(height + 1):\n",
    "        for x in range(width):\n",
    "            u = get_idx(x, y)\n",
    "            v = get_idx(x + 1, y)\n",
    "            edges.append((u, v))\n",
    "    for x in range(width + 1):\n",
    "        for y in range(height):\n",
    "            u = get_idx(x, y)\n",
    "            v = get_idx(x, y + 1)\n",
    "            edges.append((u, v))\n",
    "    unique_edges = set()\n",
    "    for u, v in edges:\n",
    "        if u < v: unique_edges.add((u, v))\n",
    "        else: unique_edges.add((v, u))\n",
    "    return vertices, list(unique_edges), skew\n",
    "\n",
    "# Scenariusze Testowe\n",
    "scenarios = [\n",
    "    {\"gen\": lambda: manual_delaunay_generator(width=10, height=10, num_points=30), \n",
    "        \"dims\": (10, 10),\n",
    "        \"desc\": \"Nieregularny (Własna Triangulacja)\"},\n",
    "    {\"gen\": lambda: generate_quad_grid(3, 3, skew=0.0), \"dims\": (3, 3), \"desc\": \"Siatka 3x3 (Kwadraty)\"},\n",
    "    {\"gen\": lambda: generate_quad_grid(4, 2, skew=0.5), \"dims\": (4, 2), \"desc\": \"Siatka 4x2 (Równoległoboki)\"},\n",
    "    {\"gen\": lambda: generate_tri_grid(2, 5), \"dims\": (2, 5), \"desc\": \"Siatka 2x5 (Trójkąty)\"},\n",
    "]\n",
    "\n",
    "output_folder = \"gif\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "print(\"Rozpoczynam generowanie animacji...\")\n",
    "for s_idx, scen in enumerate(scenarios):\n",
    "    desc = scen[\"desc\"]\n",
    "    w, h = scen[\"dims\"]\n",
    "    print(f\"\\n--- Przetwarzanie scenariusza {s_idx}: {desc} ---\")\n",
    "    vertices, edges, skew = scen[\"gen\"]()\n",
    "    points_to_check = []\n",
    "    for _ in range(2):\n",
    "        py = random.uniform(0, h)\n",
    "        shift_at_y = py * skew \n",
    "        px = random.uniform(0 + shift_at_y, w + shift_at_y)\n",
    "        points_to_check.append((px, py))\n",
    "        \n",
    "    for p_idx, point in enumerate(points_to_check):\n",
    "        try:\n",
    "            vis_anim = animate_point_location(vertices, edges, point)\n",
    "            if vis_anim:\n",
    "                filename = f\"scenariusz_{s_idx:02d}_punkt_{p_idx}.gif\"\n",
    "                full_path = os.path.join(output_folder, filename)\n",
    "                vis_anim.save_gif(full_path)\n",
    "                print(f\"    -> Zapisano: {full_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    [BŁĄD]: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam generowanie animacji...\n",
      "\n",
      "--- Przetwarzanie scenariusza 0: Nieregularny (Własna Triangulacja) ---\n",
      "    [BŁĄD]: pop from empty list\n",
      "    [BŁĄD]: pop from empty list\n",
      "\n",
      "--- Przetwarzanie scenariusza 1: Siatka 3x3 (Kwadraty) ---\n",
      "    -> Zapisano: gif\\scenariusz_01_punkt_0.gif\n",
      "    -> Zapisano: gif\\scenariusz_01_punkt_1.gif\n",
      "\n",
      "--- Przetwarzanie scenariusza 2: Siatka 4x2 (Równoległoboki) ---\n",
      "    -> Zapisano: gif\\scenariusz_02_punkt_0.gif\n",
      "    -> Zapisano: gif\\scenariusz_02_punkt_1.gif\n",
      "\n",
      "--- Przetwarzanie scenariusza 3: Siatka 2x5 (Trójkąty) ---\n",
      "    -> Zapisano: gif\\scenariusz_03_punkt_0.gif\n",
      "    -> Zapisano: gif\\scenariusz_03_punkt_1.gif\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dodatki (Analiza i Input)\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:07.928493Z",
     "start_time": "2026-01-07T01:01:07.921550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_large_procedural_graph(rows, cols):\n",
    "    \"\"\"\n",
    "    Generuje duży, poprawny graf planarny w formie siatki trójkątów.\n",
    "    Zwraca (vertices, edges).\n",
    "\n",
    "    Liczba wierzchołków V = rows * cols\n",
    "    \"\"\"\n",
    "    vertices = []\n",
    "    edges = []\n",
    "\n",
    "    # 1. Generowanie wierzchołków (V)\n",
    "    # Dodajemy mały losowy 'jitter', żeby punkty nie były idealnie w linii (bardziej realistyczne)\n",
    "    for y in range(rows):\n",
    "        for x in range(cols):\n",
    "            jitter_x = random.uniform(-0.2, 0.2)\n",
    "            jitter_y = random.uniform(-0.2, 0.2)\n",
    "            vertices.append((float(x) + jitter_x, float(y) + jitter_y))\n",
    "\n",
    "    # Helper do pobierania indeksu w liście jednowymiarowej\n",
    "    def get_idx(c, r):\n",
    "        return r * cols + c\n",
    "\n",
    "    # 2. Generowanie krawędzi (E) - łączenie z sąsiadami (prawo, góra, góra-prawo)\n",
    "    for r in range(rows - 1):\n",
    "        for c in range(cols - 1):\n",
    "            curr = get_idx(c, r)\n",
    "            right = get_idx(c + 1, r)\n",
    "            top = get_idx(c, r + 1)\n",
    "            top_right = get_idx(c + 1, r + 1) # Przekątna\n",
    "\n",
    "            # Krawędź pozioma\n",
    "            edges.append((curr, right))\n",
    "            # Krawędź pionowa\n",
    "            edges.append((curr, top))\n",
    "            # Krawędź ukośna (tworzy trójkąty)\n",
    "            edges.append((curr, top_right))\n",
    "\n",
    "            # Domknięcie krawędzi na brzegach siatki (dla estetyki, opcjonalne)\n",
    "            if c == cols - 2: # Ostatnia kolumna, krawędzie pionowe\n",
    "                edges.append((right, top_right))\n",
    "\n",
    "        # Ostatni rząd, krawędzie poziome\n",
    "        for c in range(cols - 1):\n",
    "            bottom_last = get_idx(c, rows - 1)\n",
    "            bottom_right_last = get_idx(c + 1, rows - 1)\n",
    "            edges.append((bottom_last, bottom_right_last))\n",
    "\n",
    "    return vertices, edges"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:02:57.205997Z",
     "start_time": "2026-01-07T01:02:22.053697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zakładamy, że funkcje build_graph, compute_planar_weights, generate_monotone_chains,\n",
    "# create_search_structure, query_search_tree oraz generatory są już zdefiniowane.\n",
    "\n",
    "grid_sizes = [10, 50, 100, 150, 200, 400] #, 600]\n",
    "result_list = []\n",
    "ReportsDir = \"Reports/\"\n",
    "\n",
    "# Definiujemy konfiguracje testów: nazwa i odpowiadająca jej funkcja generatora\n",
    "test_configs = [\n",
    "    ('TriGrid', generate_tri_grid),\n",
    "    ('QuadGrid', generate_quad_grid)\n",
    "]\n",
    "\n",
    "for type_name, generator_func in test_configs:\n",
    "    print(f\"Rozpoczynam benchmark dla: {type_name}\")\n",
    "\n",
    "    for N in grid_sizes:\n",
    "        # 1. Generowanie danych (używamy generatora z obecnej konfiguracji)\n",
    "        # Zakładam, że oba generatory zwracają (vertices, edges, _)\n",
    "        vertices, edges, _ = generator_func(N, N)\n",
    "        setNum = len(vertices)\n",
    "\n",
    "        # --- POMIAR CZASU BUDOWY (PREPROCESSING) ---\n",
    "        t0 = time()\n",
    "        try:\n",
    "            graph = build_graph(vertices, edges)\n",
    "            compute_planar_weights(graph)\n",
    "            separators = generate_monotone_chains(graph)\n",
    "            bst_root = create_search_structure(separators)\n",
    "            build_time = time() - t0\n",
    "\n",
    "            # --- POMIAR CZASU ZAPYTANIA (QUERY) ---\n",
    "            query_count = 100\n",
    "            test_points = [(random.uniform(0, N), random.uniform(0, N)) for _ in range(query_count)]\n",
    "\n",
    "            t1 = time()\n",
    "            for p in test_points:\n",
    "                # query_search_tree używa bst_root i skrajnych separatorów\n",
    "                query_search_tree(p, bst_root, closest_left=separators[0], closest_right=separators[-1])\n",
    "            query_time_total = time() - t1\n",
    "            avg_query_time = query_time_total / query_count\n",
    "\n",
    "            # Dodanie do listy wyników\n",
    "            result_list.append({\n",
    "                'Typ Grafu': type_name,\n",
    "                'Liczba V': setNum,\n",
    "                'Liczba E': len(edges),\n",
    "                'Czas Budowy [s]': build_time,\n",
    "                'Czas Zapytania [s]': avg_query_time\n",
    "            })\n",
    "            print(f\"  Zakończono dla V={setNum}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Błąd podczas przetwarzania {type_name} dla V={setNum}: {e}\")\n",
    "\n",
    "# Tworzenie DataFrame i zapis\n",
    "final_dataframe = pd.DataFrame(result_list)\n",
    "print(\"\\nWyniki końcowe:\")\n",
    "print(final_dataframe)\n",
    "\n",
    "# Zapis do CSV (nadpisze poprzedni plik lub stworzy nowy)\n",
    "if not os.path.exists(ReportsDir):\n",
    "    os.makedirs(ReportsDir)\n",
    "\n",
    "final_dataframe.to_csv(ReportsDir + 'Benchmark_Separatory_Full.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam benchmark dla: TriGrid\n",
      "  Zakończono dla V=121\n",
      "  Zakończono dla V=2601\n",
      "  Zakończono dla V=10201\n",
      "  Zakończono dla V=22801\n",
      "  Zakończono dla V=40401\n",
      "  Zakończono dla V=160801\n",
      "  Zakończono dla V=361201\n",
      "Rozpoczynam benchmark dla: QuadGrid\n",
      "  Zakończono dla V=121\n",
      "  Zakończono dla V=2601\n",
      "  Zakończono dla V=10201\n",
      "  Zakończono dla V=22801\n",
      "  Zakończono dla V=40401\n",
      "  Zakończono dla V=160801\n",
      "  Zakończono dla V=361201\n",
      "\n",
      "Wyniki końcowe:\n",
      "   Typ Grafu  Liczba V  Liczba E  Czas Budowy [s]  Czas Zapytania (średni) [s]\n",
      "0    TriGrid       121       320         0.005260                     0.000007\n",
      "1    TriGrid      2601      7600         0.030554                     0.000012\n",
      "2    TriGrid     10201     30200         0.136858                     0.000020\n",
      "3    TriGrid     22801     67800         0.368018                     0.000027\n",
      "4    TriGrid     40401    120400         2.526286                     0.000029\n",
      "5    TriGrid    160801    480800         4.113163                     0.000042\n",
      "6    TriGrid    361201   1081200        10.613649                     0.000056\n",
      "7   QuadGrid       121       220         0.004676                     0.000005\n",
      "8   QuadGrid      2601      5100         0.017350                     0.000010\n",
      "9   QuadGrid     10201     20200         1.677493                     0.000017\n",
      "10  QuadGrid     22801     45300         0.315954                     0.000023\n",
      "11  QuadGrid     40401     80400         0.723366                     0.000024\n",
      "12  QuadGrid    160801    320800         4.724087                     0.000088\n",
      "13  QuadGrid    361201    721200         6.532304                     0.000042\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T01:01:55.908226Z",
     "start_time": "2026-01-07T01:01:30.565992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zakładamy, że funkcje build_graph, compute_planar_weights, generate_monotone_chains,\n",
    "# create_search_structure, query_search_tree oraz generatory są już zdefiniowane.\n",
    "\n",
    "# Lista rozmiarów siatek (NxN), dla których robimy benchmark\n",
    "grid_sizes = [10, 50, 100, 150, 200, 400 , 600 ]#, 1000 ]#, 10000]\n",
    "result_list = []\n",
    "\n",
    "ReportsDir = \"Reports/\"\n",
    "\n",
    "for N in grid_sizes:\n",
    "    # 1. Generowanie danych (Tri Grid)\n",
    "    # V = N*N, E ≈ 3*N*N\n",
    "    vertices, edges, _ = generate_tri_grid(N, N)\n",
    "    setNum = len(vertices)\n",
    "\n",
    "    # --- POMIAR CZASU BUDOWY (PREPROCESSING) ---\n",
    "    t0 = time()\n",
    "    graph = build_graph(vertices, edges)\n",
    "    compute_planar_weights(graph)\n",
    "    separators = generate_monotone_chains(graph)\n",
    "    bst_root = create_search_structure(separators)\n",
    "    build_time = time() - t0\n",
    "\n",
    "    # --- POMIAR CZASU ZAPYTANIA (QUERY) ---\n",
    "    # Wykonujemy np. 100 zapytań, aby uśrednić wynik dla bardzo małych czasów\n",
    "    query_count = 100\n",
    "    test_points = [(random.uniform(0, N), random.uniform(0, N)) for _ in range(query_count)]\n",
    "\n",
    "    t1 = time()\n",
    "    for p in test_points:\n",
    "        query_search_tree(p, bst_root, closest_left=separators[0], closest_right=separators[-1])\n",
    "    query_time_total = time() - t1\n",
    "    avg_query_time = query_time_total / query_count\n",
    "\n",
    "    # Dodanie do listy w Twoim stylu\n",
    "    result_list.append({\n",
    "        'Liczba V': setNum,\n",
    "        'Liczba E': len(edges),\n",
    "        'Czas Budowy [s]': build_time,\n",
    "        'Czas Zapytania [s]': avg_query_time,\n",
    "        'Typ Grafu': 'TriGrid'\n",
    "    })\n",
    "\n",
    "    # Opcjonalnie powtórz dla QuadGrid, jeśli chcesz mieć oba w jednym pliku\n",
    "    # vertices_q, edges_q, _ = generate_quad_grid(N, N)\n",
    "    # ... analogiczny pomiar ...\n",
    "\n",
    "# Tworzenie DataFrame i zapis\n",
    "final_dataframe = pd.DataFrame(result_list)\n",
    "print(final_dataframe)\n",
    "\n",
    "# Zapis do CSV\n",
    "final_dataframe.to_csv(ReportsDir + 'Benchmark_Separatory.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Liczba V  Liczba E  Czas Budowy [s]  Czas Zapytania (średni) [s] Typ Grafu\n",
      "0       121       320         0.012304                     0.000005   TriGrid\n",
      "1      2601      7600         0.028646                     0.000011   TriGrid\n",
      "2     10201     30200         0.143160                     0.000019   TriGrid\n",
      "3     22801     67800         0.369196                     0.000023   TriGrid\n",
      "4     40401    120400         0.600867                     0.000029   TriGrid\n",
      "5    160801    480800         7.377424                     0.000037   TriGrid\n",
      "6    361201   1081200        15.703608                     0.000043   TriGrid\n"
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
